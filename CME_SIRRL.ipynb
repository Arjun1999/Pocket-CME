{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CME_SIRRL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5KEakiGgZIJ",
        "outputId": "ce48f467-156e-469d-deec-0c6b145e4629"
      },
      "source": [
        "!pip install torch torchvision pyro-ppl\n",
        "\n",
        "#import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.distributions import Normal\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "print(\"Currently using Pyro version: \" + pyro.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (0.1.2)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (4.62.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Currently using Pyro version: 1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYmXi30Rdyon"
      },
      "source": [
        "# ----------------------------------------------------- One Emotion Model [Reference]--------------------------------------------------\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVPK9qMSgbBM",
        "outputId": "51104a1e-af1f-4362-c1d3-b3b02ee64590"
      },
      "source": [
        "# data location\n",
        "#dataset_path = os.path.join(os.path.abspath('..'), \"CognitionData\", \"data_wheelOnly.csv\")\n",
        "dataset_path = \"https://desmond-ong.github.io/pplAffComp/CognitionData/data_wheelOnly.csv\"\n",
        "\n",
        "OUTCOME_VAR_NAMES = [\"payoff1\", \"payoff2\", \"payoff3\", \"prob1\", \"prob2\", \"prob3\", \"win\", \"winProb\", \"angleProp\"]\n",
        "EMOTION_VAR_NAMES = [\"happy\", \"sad\", \"anger\", \"disgust\", \"fear\", \"content\", \"disapp\"]\n",
        "OUTCOME_VAR_DIM = len(OUTCOME_VAR_NAMES)\n",
        "EMOTION_VAR_DIM = len(EMOTION_VAR_NAMES)\n",
        "\n",
        "def load_outcome_emotion_dataset(csv_file, normalize_values=True, preview_datafile=False):\n",
        "    data_readin = pd.read_csv(csv_file)\n",
        "    outcome_data = data_readin.loc[:,OUTCOME_VAR_NAMES]\n",
        "    if normalize_values:\n",
        "        ####\n",
        "        ## payoff1, payoff2, payoff3 and win are between 0 and 100\n",
        "        ## need to normalize to [0,1] to match the rest of the variables,\n",
        "        ## by dividing payoff1, payoff2, payoff3 and win by 100\n",
        "        ####\n",
        "        outcome_data.loc[:,\"payoff1\"] = outcome_data.loc[:,\"payoff1\"]/100\n",
        "        outcome_data.loc[:,\"payoff2\"] = outcome_data.loc[:,\"payoff2\"]/100\n",
        "        outcome_data.loc[:,\"payoff3\"] = outcome_data.loc[:,\"payoff3\"]/100\n",
        "        outcome_data.loc[:,\"win\"]     = outcome_data.loc[:,\"win\"]/100\n",
        "    outcome_data_tensor = torch.tensor(outcome_data.values).type(torch.Tensor)\n",
        "    \n",
        "    emotion_data = data_readin.loc[:,EMOTION_VAR_NAMES]\n",
        "    if normalize_values:\n",
        "        ## note that emotions are transformed from a 9 point Likert to [0,1] via emo <- (emo-1)/8\n",
        "        emotion_data   = (emotion_data-1)/8\n",
        "    emotion_data_tensor = torch.tensor(emotion_data.values).type(torch.Tensor)\n",
        "    \n",
        "    if preview_datafile:\n",
        "        print(\"Preview of first 3 rows:\")\n",
        "        print(outcome_data.loc[0:2,:])\n",
        "        print(emotion_data.loc[0:2,:])\n",
        "    \n",
        "    data = torch.cat((outcome_data_tensor, emotion_data_tensor), 1)\n",
        "    \n",
        "    preprocessed_data = pd.concat([outcome_data, emotion_data], axis=1)\n",
        "\n",
        "    shuffled_data = preprocessed_data.sample(frac=1)\n",
        "    divided_parts = np.array_split(shuffled_data, 4)  \n",
        "\n",
        "    train_set = pd.concat([divided_parts[0], divided_parts[1]], axis = 0)\n",
        "    train_set = pd.concat([train_set, divided_parts[2]], axis = 0)\n",
        "    test_set  = divided_parts[3] \n",
        "    \n",
        "    train_set_tensor = torch.tensor(train_set.values).type(torch.Tensor)\n",
        "    test_set_tensor  = torch.tensor(test_set.values).type(torch.Tensor)\n",
        "    \n",
        "    return train_set_tensor, test_set_tensor\n",
        "    # return data\n",
        "\n",
        "\n",
        "# reads in datafile.\n",
        "print(\"Reading in dataset...\")\n",
        "train_set, test_set = load_outcome_emotion_dataset(csv_file=dataset_path, preview_datafile=True)\n",
        "N_samples = train_set.shape[0]\n",
        "\n",
        "print(\"Shape of train set: \", train_set.shape)\n",
        "print(\"Shape of test set: \", test_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading in dataset...\n",
            "Preview of first 3 rows:\n",
            "   payoff1  payoff2  payoff3  prob1  prob2  prob3  win  winProb  angleProp\n",
            "0     0.50     0.75      0.9   0.30   0.52   0.18  0.5     0.30      0.921\n",
            "1     0.15     0.70      0.8   0.45   0.29   0.26  0.8     0.26      0.873\n",
            "2     0.50     0.75      0.9   0.30   0.52   0.18  0.5     0.30      0.467\n",
            "   happy    sad  anger  disgust  fear  content  disapp\n",
            "0  0.625  0.000  0.000     0.25   0.0    0.625   0.375\n",
            "1  0.875  0.000  0.000     0.00   0.0    0.000   0.000\n",
            "2  0.625  0.125  0.125     0.00   0.0    0.250   0.500\n",
            "Shape of train set:  torch.Size([1156, 16])\n",
            "Shape of test set:  torch.Size([385, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAU4u44LgcyB"
      },
      "source": [
        "def compute_appraisal(outcome_data):\n",
        "    # We have simple hard-coded appraisals, for illustration\n",
        "    # This is following Ong, Zaki, & Goodman (2015)\n",
        "    # the outcome data columns are, in order:\n",
        "    # [\"payoff1\", \"payoff2\", \"payoff3\", \"prob1\", \"prob2\", \"prob3\", \"win\", \"winProb\", \"angleProp\"]\n",
        "    # the 3 appraisal variables are: \n",
        "    #     amount won (\"win\"),\n",
        "    #     Prediction Error PE = win - EV, where EV = prob1*payoff1 + prob2*payoff2 + prob3*payoff3\n",
        "    #     absolute value of PE\n",
        "    \n",
        "    # if outcome_data only has 1 observation, reshape so vectorization works\n",
        "    if(len(outcome_data.shape)==1):\n",
        "        outcome_data = outcome_data.view(1,9)\n",
        "        print(outcome_data.shape)\n",
        "    \n",
        "    # initializing appraisalVals\n",
        "    appraisalVals = torch.zeros(size=(outcome_data.shape[0],3))\n",
        "    appraisalVals[:,0] = outcome_data[:,6] # amount won\n",
        "    \n",
        "    # Expected value\n",
        "    EV = outcome_data[:,0] * outcome_data[:,3] + \\\n",
        "         outcome_data[:,1] * outcome_data[:,4] + \\\n",
        "         outcome_data[:,2] * outcome_data[:,5]\n",
        "    \n",
        "    # prediction error and absolute PE\n",
        "    appraisalVals[:,1] = appraisalVals[:,0] - EV\n",
        "    appraisalVals[:,2] = abs(appraisalVals[:,1])\n",
        "    return(appraisalVals)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRxKWHwwgctq"
      },
      "source": [
        "# emotion data splice dimension\n",
        "\n",
        "# Happy           ->  OUTCOME_VAR_DIM\n",
        "# Sad             ->  OUTCOME_VAR_DIM + 1\n",
        "# Anger           ->  OUTCOME_VAR_DIM + 2\n",
        "# Disgust         ->  OUTCOME_VAR_DIM + 3\n",
        "# Fear            ->  OUTCOME_VAR_DIM + 4\n",
        "# Content         ->  OUTCOME_VAR_DIM + 5\n",
        "# Disappointment  ->  OUTCOME_VAR_DIM + 6\n",
        "\n",
        "def fit_regression_model(data):\n",
        "    # define the parameters that control the gaussian prior over the regression coeffs.\n",
        "    # mean = 0, scale = 1\n",
        "    coeff_mean_prior = torch.tensor(0.0)\n",
        "    coeff_scale_prior = torch.tensor(1.0)\n",
        "    \n",
        "    # sample b_0 (intercept) and b_1 to b_3 (regression coeffs)\n",
        "    b_0 = pyro.sample(\"b_0\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
        "    b_1 = pyro.sample(\"b_1\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
        "    b_2 = pyro.sample(\"b_2\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
        "    b_3 = pyro.sample(\"b_3\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
        "    \n",
        "    # loop over observed data\n",
        "    with pyro.plate(\"map\"):\n",
        "        outcome_data = data[:, :(OUTCOME_VAR_DIM)]\n",
        "        # Here, for simplification, we are only taking one emotion variable (happy)\n",
        "        # instead of all 8 emotions\n",
        "        emotion_data = data[:, OUTCOME_VAR_DIM + 6]  \n",
        "        appraisal_vars = compute_appraisal(outcome_data)\n",
        "        \n",
        "        # run the regression forward\n",
        "        prediction = b_0 + b_1 * appraisal_vars[:,0] + b_2 * appraisal_vars[:,1] + b_3 * appraisal_vars[:,2]\n",
        "        # condition on the observed data\n",
        "        pyro.sample(\"obs\", Normal(prediction, 1), obs = emotion_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLdiJzb9gcry"
      },
      "source": [
        "def fit_regression_guide(data):\n",
        "    mean_b0_param  = pyro.param(\"guide_mean_b0\",  torch.tensor(0.0))\n",
        "    scale_b0_param = pyro.param(\"guide_scale_b0\", torch.tensor(1.0))\n",
        "    mean_b1_param  = pyro.param(\"guide_mean_b1\",  torch.tensor(0.0))\n",
        "    scale_b1_param = pyro.param(\"guide_scale_b1\", torch.tensor(1.0))\n",
        "    mean_b2_param  = pyro.param(\"guide_mean_b2\",  torch.tensor(0.0))\n",
        "    scale_b2_param = pyro.param(\"guide_scale_b2\", torch.tensor(1.0))\n",
        "    mean_b3_param  = pyro.param(\"guide_mean_b3\",  torch.tensor(0.0))\n",
        "    scale_b3_param = pyro.param(\"guide_scale_b3\", torch.tensor(1.0))\n",
        "    # sample coefficients from Normal(mean, scale)\n",
        "    pyro.sample(\"b_0\", Normal(mean_b0_param, scale_b0_param))\n",
        "    pyro.sample(\"b_1\", Normal(mean_b1_param, scale_b1_param))\n",
        "    pyro.sample(\"b_2\", Normal(mean_b2_param, scale_b2_param))\n",
        "    pyro.sample(\"b_3\", Normal(mean_b3_param, scale_b3_param))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx_hRkPWOuXM"
      },
      "source": [
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "          idx = idx.item()\n",
        "        except:\n",
        "          idx = idx\n",
        "        return self.data.iloc[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "SdzdZiPngcpd",
        "outputId": "551e80f5-309b-4c20-a503-ddf95a5639e3"
      },
      "source": [
        "# this line clears pyro's parameter store.\n",
        "pyro.clear_param_store()\n",
        "\n",
        "num_iterations = 1000\n",
        "\n",
        "# setup the optimizer with some learning rate\n",
        "optimizer = Adam({\"lr\": 0.005})\n",
        "\n",
        "# setup the inference algorithm\n",
        "svi = SVI(fit_regression_model, fit_regression_guide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "# Splitting into training and testing datasets\n",
        "# train_size = int(0.75 * len(outcome_emotion_dataset))\n",
        "# test_size = len(outcome_emotion_dataset) - train_size\n",
        "# train_dataset, test_dataset = torch.utils.data.random_split(outcome_emotion_dataset, [train_size, test_size])\n",
        "\n",
        "# print(train_dataset.dataset)\n",
        "# print(outcome_emotion_dataset)\n",
        "\n",
        "# do gradient steps\n",
        "losses = []\n",
        "for thisIteration in range(num_iterations):\n",
        "    # calculate the loss and take a gradient step\n",
        "    thisLoss = svi.step(train_set)\n",
        "    losses.append(thisLoss)\n",
        "    if thisIteration % 100 == 0:\n",
        "        print(\"[iteration %04d] loss: %.4f\" % (thisIteration + 1, thisLoss / float(N_samples)))\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(\"ELBO\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iteration 0001] loss: 3.4071\n",
            "[iteration 0101] loss: 1.3019\n",
            "[iteration 0201] loss: 1.0224\n",
            "[iteration 0301] loss: 0.9790\n",
            "[iteration 0401] loss: 1.2312\n",
            "[iteration 0501] loss: 0.9615\n",
            "[iteration 0601] loss: 0.9731\n",
            "[iteration 0701] loss: 0.9526\n",
            "[iteration 0801] loss: 0.9557\n",
            "[iteration 0901] loss: 0.9637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 207
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcZZ3v8c+v16SzdhZCNghLROMgASMEUWcUDQiMcEcBuV6NyB2ud3DGWa7eoM7kXpURdZRFGZRhuWFEEFEEIQIhBCUKgU4IIQRCOiEhezrpJUl3eqv63T/qVPfp7qo+p7qrujud7/v1qldXPec5p55K5XV+9ezm7oiIiPSmaLALICIiQ5+ChYiIRFKwEBGRSAoWIiISScFCREQiKViIiEgkBQsREYmkYCHSB2a21cyOmNnh0OPHZvZ5M1uZ5Zxnzaw5yNtgZn8ws9O75bnEzF40s0YzO2Bm95nZjIH5VCLZKViI9N1fuvvo0ONLMc75kruPBiYAzwL/mT5gZp8Cfg7cDEwC3g20ACvNrDLvpRfJgYKFyCBw9wTwADAHwMwM+AHwbXf/ubsfcfc9wH8HDgP/MGiFFUHBQmRQmFkZ8BnghSDpNOAE4JfhfO6eBH4FfGxACyjSTclgF0DkKPYbM2sPvf4K0BZxzq1m9m/ASKAZ+KsgfVLwd3eGc3aHjosMCtUsRPruMncfH3r8R4xz/s7dx5MKFpcAD5nZe4D9wfGpGc6ZGjouMigULEQGgbsn3f05oBpYAGwEdgCXh/OZWRHwSWD5gBdSJETNUCL5Z2Y2Ipzg7s0ZMp1LqoP7NXd3M/tfwH+Y2Q7g18B44F+BscBNhS+2SHam/SxEcmdmW4EpQCKUvAx4BLgnwymlwNPAfCDdz7EHuM3dOwKBmV0KfINUEGkBngS+6u7b8/wRRHKiYCEiIpHUZyEiIpEULEREJJKChYiIRFKwEBGRSMNy6OykSZN81qxZg10MEZGjyurVq/e7++RMx4ZlsJg1axZVVVWDXQwRkaOKmW3LdkzNUCIiEqlgwcLMTjOztaHHQTP7ezObYGbLzGxT8LcyyG9mdquZVZvZOjM7K3SthUH+TWa2sFBlFhGRzAoWLNx9o7vPdfe5wHuBJuBhYBGw3N1nk1rvZlFwyseB2cHjWuB2ADObACwGzgHOBhZrIxgRkYE1UM1Q5wOb3X0bcCmwJEhfAlwWPL8UuNdTXgDGm9lU4AJgmbvXunsdqSUVLhygcouICAMXLD4N3B88n+Lu6TX795BaXwdgOhBe/2ZHkJYtvQszu9bMqsysqqamJp9lFxE55hU8WAQ7gn2CbjuAAXhqYaq8LE7l7ne4+zx3nzd5csaRXyIi0kcDUbP4OLDG3fcGr/cGzUsEf/cF6TuBmaHzZgRp2dJFRGSADESwuIrOJiiAR4H0iKaFpJZ0Tqd/LhgVNR9oCJqrngQWmFll0LG9IEgbFBv3HKJqa+1gvb2IyKAo6KQ8MxtFaqP5/xFKvhF40MyuAbYBVwTpS4GLSO0c1gRcDeDutWb2LeClIN833X3Q7tYX3PwHALbeePFgFUFEZMAVNFi4eyMwsVvaAVKjo7rndeC6LNe5G7i7EGUUEZFomsEtIiKRFCxERCSSgoWIiERSsBARkUgKFiIiEknBQkREIilYiIhIJAULERGJpGAhIiKRFCxERCSSgoWIiERSsBARkUgKFiIiEknBQkREIilYiIhIJAULERGJpGAhIiKRFCxERCSSgoWIiERSsBARkUgKFiIiEknBQkREIilYiIhIJAULERGJpGAhIiKRChoszGy8mT1kZm+Y2etmdq6ZTTCzZWa2KfhbGeQ1M7vVzKrNbJ2ZnRW6zsIg/yYzW1jIMouISE+FrlncAjzh7u8EzgBeBxYBy919NrA8eA3wcWB28LgWuB3AzCYAi4FzgLOBxekAIyIiA6NgwcLMxgEfAu4CcPdWd68HLgWWBNmWAJcFzy8F7vWUF4DxZjYVuABY5u617l4HLAMuLFS5RUSkp0LWLE4CaoB7zOxlM7vTzEYBU9x9d5BnDzAleD4d2B46f0eQli1dREQGSCGDRQlwFnC7u58JNNLZ5ASAuzvg+XgzM7vWzKrMrKqmpiYflxQRkUAhg8UOYIe7rwpeP0QqeOwNmpcI/u4Lju8EZobOnxGkZUvvwt3vcPd57j5v8uTJef0gIiLHuoIFC3ffA2w3s9OCpPOBDcCjQHpE00LgkeD5o8DnglFR84GGoLnqSWCBmVUGHdsLgjQRERkgJQW+/t8C95lZGbAFuJpUgHrQzK4BtgFXBHmXAhcB1UBTkBd3rzWzbwEvBfm+6e61BS63iIiEFDRYuPtaYF6GQ+dnyOvAdVmuczdwd35LJyIicWkGt4iIRFKwEBGRSAoWIiISScFCREQiKViIiEgkBQsREYmkYCEiIpEULEREJJKChYiIRFKwEBGRSAoWIiISScFCREQiKViIiEgkBQsREYmkYCEiIpEULEREJJKChYiIRFKwEBGRSAoWIiISScFCREQiKViIiEgkBQsREYmkYCEiIpEULEREJJKChYiIRFKwEBGRSAUNFma21cxeNbO1ZlYVpE0ws2Vmtin4Wxmkm5ndambVZrbOzM4KXWdhkH+TmS0sZJlFRKSngahZfNjd57r7vOD1ImC5u88GlgevAT4OzA4e1wK3Qyq4AIuBc4CzgcXpADOcbdxziNb25GAXQ0QEGJxmqEuBJcHzJcBlofR7PeUFYLyZTQUuAJa5e6271wHLgAsHutADae/BZi64+Q8sfnT9YBdFRAQofLBw4CkzW21m1wZpU9x9d/B8DzAleD4d2B46d0eQli29CzO71syqzKyqpqYmn59hwDUcaQOgamvdIJdERCSlpMDX/4C77zSz44BlZvZG+KC7u5l5Pt7I3e8A7gCYN29eXq4pIiIpBa1ZuPvO4O8+4GFSfQ57g+Ylgr/7guw7gZmh02cEadnSRURkgBQsWJjZKDMbk34OLADWA48C6RFNC4FHguePAp8LRkXNBxqC5qongQVmVhl0bC8I0kREZIAUshlqCvCwmaXf5+fu/oSZvQQ8aGbXANuAK4L8S4GLgGqgCbgawN1rzexbwEtBvm+6e20Byy0iIt0ULFi4+xbgjAzpB4DzM6Q7cF2Wa90N3J3vMg5Vrh4XERliNINbREQiKVgMQamWOxGRoUPBYghSM5SIDDUKFiIiEknBQkREIilYiIhIJAULERGJpGDRRz4AvdAaFSUiQ4WCxRCmUVEiMlQoWPSRbuQicixRsBjC1AwlIkOFgkUfqWIhIscSBYsC+lP1fuoaWwe7GCIi/aZg0UdRo6HaEkn+652r+Ozdq/rxHn0+VUQkrxQs+ijqPp4M7vRv7jlc+MKIiBSYgkWBeT96N9TBLSJDhYJFH0U1ERm604vI8KFgUSD9qVGIiAw1ChZ9FBUM1DktIsOJgkUfKRiIyLFEwUJERCIpWBRIf2oe6u8QkaEmVrAwsy+b2VhLucvM1pjZgkIXbjhQc5WIDAdxaxZfcPeDwAKgEvgscGPBSnUUiAoCqh2IyHASN1ikJw1cBPynu78WSpMMVKMQkeEkbrBYbWZPkQoWT5rZGCAZ50QzKzazl83sseD1SWa2ysyqzewXZlYWpJcHr6uD47NC17g+SN9oZhfk8gELpZA1B03oE5GhJm6wuAZYBLzP3ZuAUuDqmOd+GXg99Pq7wE3ufipQF1w7/R51QfpNQT7MbA7waeDdwIXAv5tZccz3LpjoZqh+XFtNWCIyxMQNFucCG9293sz+G/ANoCHqJDObAVwM3Bm8NuAjwENBliXAZcHzS4PXBMfPD/JfCjzg7i3u/hZQDZwds9yDZiD26BYRGShxg8XtQJOZnQH8E7AZuDfGeTcDX6WzyWoiUO/u7cHrHcD04Pl0YDtAcLwhyN+RnuGcDmZ2rZlVmVlVTU1NzI/Vd1GhQKFCRIaTuMGi3VM/lS8FfuzutwFjejvBzC4B9rn76n6WMRZ3v8Pd57n7vMmTJ/fpGht2HeTPv7+C5zcfyF+5+nGu+i5EZKiIGywOmdn1pIbMPm5mRaT6LXpzHvAJM9sKPECq+ekWYLyZlQR5ZgA7g+c7gZkAwfFxwIFweoZz8qotkWTbgSaOtLVH5o1qZspHK1RvfRdLX93Nlx94uf9vIiISQ9xgcSXQQmq+xR5SN+zv93aCu1/v7jPcfRapDupn3P0zwArgU0G2hcAjwfNHg9cEx58JajOPAp8ORkudBMwGXoxZ7pyk949IxhjnFRkL+jODO8a5f3PfGh5Zu6vvbyIikoNYwSIIEPcB44LmpWZ3j9Nnkcn/Bv7RzKpJ9UncFaTfBUwM0v+R1OgrgjkdDwIbgCeA69w90cf37lW62Uf9DSIiXZVEZwEzu4JUTeJZUpPxfmRmX3H3h3o9MeDuzwbn4u5byDCayd2bgcuznH8DcEOc9+qPdM0izkimQs7g1kAqERlqYgUL4Ouk5ljsAzCzycDTdA6BHVbyca/Ox0KC6uAWkaEibp9FUTpQBA7kcO5Ro7NmESNzjpPy7vjDZtbvjJya0u0aqmKIyNAQt2bxhJk9CdwfvL4SWFqYIg2ezl/y+btJp5u0/nXpGwBsvfHiGOfk7e1FRPIiVrBw96+Y2SdJDYcFuMPdHy5csQZHUVBXinOzjt5Wtf93fDVDichQEbdmgbv/CvhVAcsy6NI352ScYFHAtaFERIaaXoOFmR0i833PAHf3sQUp1SDp6LMY5Fu9mqFEZKjpNVi4e69Legw3HT0WsZqhIo7rhi8iw8iwG9HUH501i/7r1zwLNWKJyBCjYNFFMIM71qS8eDf0vtz2VSsRkaFGwSLEchh8VMi1oUREhhoFi5Bc+iyi9G+nPBGRoUXBIqTI0gsJ5mFtKA8/z+32r132RGSoUbAIyWWJ8lzo3i8iRzsFi5BcliiPnMEdOp5rrFBsEZGhRsEiJJclyqP0rxkql7wKLSJSeAoWGcS6/ca8R7sXtqagWCEiA0HBIsRyWHQ2cgZ3+HnON3RFABEZWhQsQiyH0VBRws1DhZyRrbAiIgNBwSKkKIfNj+IOnTXLvWahPgsRGWoULEJyWaI8rr7cy3M5RaFCRAaCgkVILkuU59K0VMgf/6pYiMhAULAIyWmJ8lxmcOf4+z+nZijVLURkAChYhEUsUd7X/oHc+yxSJ8RZ2DB97V9WbWft9vocSyYiEk/sbVWPBR17Xme5uz/88s6O59FDZ/s+g7vjvBxO/MpD6wDYeuPFfXw3EZHsVLMIidr86JUcfrn3awZ3TrlFRAqvYMHCzEaY2Ytm9oqZvWZm/zdIP8nMVplZtZn9wszKgvTy4HV1cHxW6FrXB+kbzeyCgpU5+Jvt3m6hdqFcAoBmcIvI0a6QNYsW4CPufgYwF7jQzOYD3wVucvdTgTrgmiD/NUBdkH5TkA8zmwN8Gng3cCHw72ZWXIgCdyxRno+1ocLPCznPQvUQERkABQsWnnI4eFkaPBz4CPBQkL4EuCx4fmnwmuD4+Zb6KX8p8IC7t7j7W0A1cHYhytyxRHleRkN1GQ6Vk3QAyKWDW0SkkAraZ2FmxWa2FtgHLAM2A/Xu3h5k2QFMD55PB7YDBMcbgInh9AznhN/rWjOrMrOqmpqavpU3Yonyvm67OlSX+1i15QCv7mjIW1lEZPgqaLBw94S7zwVmkKoNvLOA73WHu89z93mTJ0/u20UilijvGC1Frkty5FiOAaotXHnHC/zlj1cOzJuJyFFtQEZDuXs9sAI4FxhvZukhuzOA9HjUncBMgOD4OOBAOD3DOXkVVXMIH4/c/KjvrVC5LfehdigRGQCFHA012czGB89HAh8DXicVND4VZFsIPBI8fzR4TXD8GU/dCR8FPh2MljoJmA28WJAyB3/dobktQUt7Imve6Ht0aJ5FAW/oChUiMhAKOSlvKrAkGLlUBDzo7o+Z2QbgATP7NvAycFeQ/y7gP82sGqglNQIKd3/NzB4ENgDtwHXunv0u3g/hJcrf+c9PMGZECa/+n86RuuGKR7KAQ2cL2sQlItIHBQsW7r4OODND+hYyjGZy92bg8izXugG4Id9l7K77EuWHmtuZtehxfvflD/KuqWO7liniWl0n5eWvjCs27uPqe16KXxARkTzQDO6QbEuUP7F+T+p4uM8iauhsl+e5zuDOnv/Hz1THzisiki8KFiHZligvDqoc1qUHvDPPz17Yxm9f2dXlHPeMWWNR05KIDDVaSDCD7jfrjmARSgvXPr7xm/UA/OUZ0zJfL69l826v83hxEZEsVLMIyTZ0NlN6dDNU3+/i2ilPRIYaBYuQjhnc3SJBcTpa9HWeRR/3s8h3XhGRvlKwCLFuo6HS0s1QYclk/OvmsxO6+5UUKkRkIChYhHRMyuuebuk+i9ByH4WsWeSSV9FCRAaAgkVIeony7hPuitOtUDkNne3HTnlaolxEhhgFi5BszVBFGUZD5SKf/QpxL1W1tZa9B5vz9r4icmxTsAjpXO4jc3q4ZhG13Ef/mqFyqlpk9KmfPM+FN/8htzcWEclCwSKTbKOhsmcZNE72mktdU9vAFkZEhi0Fi27Mev5YL87wr1TItaGy5d+6v5G12+t75I2zs5+ISH8oWHRj9LxZZxoNlduqszmuDZUl+0//sCXjtTXXQkQKTcGiGwee29R1W9biDH0WOY2GytO9PNtMcoUKESk0BYtu3OGVbvtSZ1obqr6pldd2Zd+/Os5OeVv3N7LkT1t7ntvtdXNbgle212cdjaWKhYgUmhYSjKHjF33op/01S6oA2HrjxZHnZ2smuvynz1NzqIUr3zeTEaXFWfN/5aF1/PaVXVz47uN7XpvcmsRERPpCNYsYiqI2584gzgrl9U2tsa71StCp3dja3vN9FChEZAAoWMSQ6+14095DXHbbHzvPz3KBrOndXvcWq9zVDCUihadgEUP613vc+sXTr+/rfoWOZ/sONdNwJDX/Id18FNWM1NkKlrkE3UdbqbYhIvmmYBFD+t7bh9aoLucDnH3Dct7/neWp9CCt+zyJbEN3s127+/madyEi+aZgEUP6l7vFrFt0v7d3v3c3tiZS6cGBnjWLrq97e9dM8yxUsxCRfNNoqBjSe1dknucQfWOOnJORw94YGc8PPT/c0k57op8XFBHpRsEiht7u9XF+xEfN4O5es+hxzRw6uP9s8ZPRBRIRyZGaoWLorfYQZ45DVJYewaLb8d6bodTsJCKFp2ARQ/pWnOmmvWzD3ujzI4NF78d77+B2DZ0VkYIrWLAws5lmtsLMNpjZa2b25SB9gpktM7NNwd/KIN3M7FYzqzazdWZ2VuhaC4P8m8xsYaHKnE3H0NkM9+z/ed+a6PMzNEPNWvR4j+t3vu6aN7JmEVmC3GyvbWJzzeE8X1VEjmaFrFm0A//k7nOA+cB1ZjYHWAQsd/fZwPLgNcDHgdnB41rgdkgFF2AxcA5wNrA4HWAGSufQ2ZijobKcn03coa6ZmptSfRYRfSJJZ8XGfbGbqz74vRWc/4PfxyuUiBwTChYs3H23u68Jnh8CXgemA5cCS4JsS4DLgueXAvd6ygvAeDObClwALHP3WnevA5YBFxaq3JkUupWnZ59Ft6GzljlfZ/7e3f3Ht7j6npc46fqlfS2iiBzjBqTPwsxmAWcCq4Ap7r47OLQHmBI8nw5sD522I0jLlt79Pa41syozq6qpqel+uF8erNrOrEWPc7il59pMYS9sOZAxPecO7h7NUKlokcw4ItYjO9m3HmjsvQC9aG1PMudfnuCRtTv7fI1c3fz0m2zcc2jA3k9EohU8WJjZaOBXwN+7+8HwMU+1i+Tlh7u73+Hu89x93uTJk/NxyQ4vv51ayG9H3ZFe8336jheATJPyovfr3newmVmLHufRV3Zlz5fhOnH+BRP9mNJd39RKU2uCbz32ep+vkYsjrQlufnoTl//kTwPyfiIST0GDhZmVkgoU97n7r4PkvUHzEsHf9EJKO4GZodNnBGnZ0gdcW3v0ZLdDzT33vY5Ts9i0L9WhfP+qt7MuJJjpnh8n2rYn+hGPOwLfwA65autPmUUk7wo5GsqAu4DX3f2HoUOPAukRTQuBR0LpnwtGRc0HGoLmqieBBWZWGXRsLwjSBlxrjJnRew8290iLuu0lvTMgPL/lAH93/8sdx57bVMOe4JrZO7h7v364ZlG1tZYfPrUxokSd4i5x0hfLNuzlM3e+0CVNe3OIDE2FnMF9HvBZ4FUzWxukfQ24EXjQzK4BtgFXBMeWAhcB1UATcDWAu9ea2beAl4J833T32gKWO6vWGDWLuqZMNYvoGdyZbsrtSeezd70Yuk7Pcz1Gn0UidPxTP3kegH9ccFqv54SvXyh/fW9qA6lE0jt2I0z0MkxZRAZPwYKFu68k+xSB8zPkd+C6LNe6G7g7f6XrmzjBIlNTVdTtNlswqd7Xda5Dog+joQ42t9Geof0q7vpR6bcs5A/+tkSS4qLUToFJLZkrMiRpBncOWmLcYB9Z27ODOs48izi/pDN1VEfNs1i5aT+JDO3/zTECX6psqXMLcQsPKhNdPlf6uSoWIkOLgkUOWtoSkXl+UbWdtcE2qJ3iNENFy9TpG9VnUVZcRHuGMbdHWqM/C/RvJFWU9Ha14Q74bLUnERlcChY5aIn5a/xQc9f5GJE1i2S82eGZmo5S+1lkP6espKhLM1Rpcep9mmMEvnTZoDCLFaaDRVsomHWPa5/48UoerNqOiAwuBYscxP013l30aKh4N+JN+3qu13TxrSt5asOerOeYda0dlBanvvIjcYNFhmao9kSSHzy1kYYMnfk5sfT1Oq+ergWlg+e6HQ189aF1/XsfEek3BYsc7MkwLDaOyM2PvH/NPd9+PPuEubZEMmOwaIrbDJWh8Ms27OVHz1Tz7cc35FjSrtJ9Fu1ZahZael1k6FCwGABxhs4Wan5Ba3uySzNUw5FUbSBuLSk9OilcvPR8k7i1k2yi+iw0MEpk6FCwKIBc7/sOGYe35kNLezJjreVIW+/rXKW9uTfV9FXIPotwzSI8GiqcvrO+96VWRKSwFCwKoK1bR3ScPotCzS/oXrMIp8dx3c+j9+uIK5F0frR8U0dfR7pPPzzKq6OGZV2bpK75fy8hIoNHwaIAui8LEjXyyN0LNkS1LZE5ELXGWHspXJvIR+meem0PP1j2Jt998g2gcy5FtnkW4ZrFwSP97EwXkX5RsCiA7r/aozqTk164ZqjW9kSPmg7Abc9UR54btZhfa3uS5a9Hbyubtu9QC9DZsV0UPAmXL1PgyMXvXt3Nsxv3RWcUkZwUcm2oY1b3mkRjxD4YyaRz24rom3dftCYy91ls3Bu9X0RLe+hzeKpTPNyp/dSGvTy1YS+//OK5VG2tY+q4EVx2Zo+tRjrUNbUCUFlRBoT7LDI0Q9EzWLy++yA7647w0TlTyCa9ze3WGy+O+ngikgMFiwI40Nja5XWcmsWrOxsKUpbWLB3ccazctL/juQOfvP1PbNh9kFuvOrNLvvqmNr77RKppaeaEkbz3xAnUN7XS2Jpg+viRHfnSkxXHjigFOmsY4ZrFXSvfAlLzLLqX++O3PAfECwRNre1UlOm/t0i+qBmqAOq7TVZrbO29ZrHqrcw77EH/V1/N1sEdR/pXetqG3am9q7qPjArXNjbsTtVYPvS9FZx34zNd8qVv/ukVZtO9FuGhs+G1tfqz9Mf3nui5DPuVP32+Y6VbEcmNgsUAaGrpvWZx89Obsh6rKC3u13u3JqI7z+98bkvkdcIBonsz24HDLT3yH2zuGSDT13gzaALLtJBgmln2TZviDONNN3mFrXqrlmUb9rL89b3MWvS4huOK5EDBIo8+OHtSxvRMu+fFNbKsa7AIN+vEEacZqrcZ4GnhK9Q2dv08teFmt15u5OkjD7yUWusp3WfRmkhysLmNBTf9vkv+bBMV46zRFT7V3Zm16PGO11/82WoAXt3RfcFHEclGwSKPsg2RXfL8tj5fs3uwGFGa21fWmkjk1AwVZ2Z394X9wn00vb1T+Ob/9oEmSoJFDVvbk6zaUtsxATAtW7mPtCZ4YcsBZi16nFd6rPDbU/ehzNqyVSR36gHMYtMNH2f213+X0zlx11vKRUVp169oRI7NUj974e1Y+W5dvok/bd7PC1syb0IYvnG/tb+xy7Gfr+p8jx11R9jd0Nm84+6c/8Pfc+G7j++yfMeHvr+i43lLe5KR3T6X0bV5Knx7b2xtZ8UbqeGxf9p8gDNmju9R3nBfT3Nb5ppIei+QOCv+ihzrVLPIIr3gXi4KESxGdKtZdL+p5ssPl72ZNVBA6td/ZUVp5HXu+MMWzv1OZ8d2e9LZUtPIvz+7OeMugpAaopvpfp2t+aypNdFxg//uE29knEfS5fpZanw3LH2dk65fyqxFj1O9L3ooscixTMGim99+6QPcfOXcPp1biFnG40Z2vUHnWrPIp85RTPGt2VbX8Xz123UZ89z13Fs9mqCga3NXuA+iqTVBuCgrq/fT3SNrd3Hv81uZtehx6rN8LzvqOmtAz26sYfEj69l3KLeVhZe+upsn1u/O6RyRo5GCRTenzxjX68Sy3nzoHZPzXBqYMqa8y+tR5YMXLPYf7jnCKMqVd7zQ8XxLTWPGPFv2N3bM00ira2rjnj9u7XgdHp7b1NLe0TkO2fft/pdHXgNgV4xRT0+/vpclz2/jX2N09l/+kz/xD79YSyLp/M19a/jiz/K3fpbIUKVgEdN//8BJvR7/xsXv4l8umdOv95g2bkSPtOPGdg0WX7ngtH69x9GqIVQ7aOxWs7hmSRVtiSQ/fibzEOTu814ySTfB/WbtLjbuOcRXH3qlS/OWu3O4pZ07n9vCS1vrePjlnZzytaUdx//bnat6vX5dY2vOtRaRoUTBIqbZU0Z3eV3SrUnmfbMmUDmqLPI6vfWlZtpc6fixXQPIuJHR7wFw1dkzI/OcPHlUl9dXzos+Zyh4sGp7j+VK9h5s5t+eejNj/v0Z5oH05rqfr+HBqh0de6mv3V7PSdcv5UPfW5F1mPHK6v00tyVoTySpbWxl/c4GDhxu4btPvMG+g82c853lnH3D8i61oPU7G/jp7zf3WpZ9B5vZXtsEpEbbLX11d+zl4oVe9cwAAA9GSURBVNfvbIi9fa5IFI2Giinc0rHmnz/GL6u2853fdS5xcfr0cV3y/3HRR3h6w14WP/pal/Q7PzePa5ZknkWcqTXl1OPGdHkdp9vgsrnT+M5fvYf7X+xs8580urzHTTPcWf7O48cwYXTPQDRxVFmP5UsG27INPRcv7K32EGceSVh1sH3ti2/VMu/ESi677Y9At/kkGazf2cDNT2/q0Yeyed/hjsUlT/7aUn77pQ+wdnsd/xw0kz27sYY508Zy3YdPJZF0Jo8p52BzG28faOKKnz5PU2uCrTdezL8/u5lbl2/ig7Mnccl7pvKp986ket9hTjt+TI+y1Bxq4ZIfreSTZ83gB1ec0eXYyk37eceU0RxsbmP1tjqufN8J3LaimtHlJfyXs6YzdkQpLe0Jvvbr9byyo54fXH5GlxFnW/c3csKEio6FIMOaWtvZVd/MqceN7nEsk95Go63acoCZEyqYluPcIikMG45bV86bN8+rqvq/rENLe4LTvvEEADf8lz/j6w+v56qzZ/Kdv3oPTa3tXPKjlWypaeS5r36YmRMqADomf6XXLwpPBgO45/PvY3xFKfetepuHVu/gv55zAhNHlfGjZ6r54p+fwrYDjfxufWpP7XknVvLzv57Ph763gj0Hm3n4b97Pe2aM55SvLWX6+JHsrD/Cn00fy/qdqWU4vvfJ91BzuIUvnHcSI8uKuf3Zzdy18i0e+9sPMHZkCcs27OXLD6zt8TnPnjWBB794Lrc8vYmbnn6Ts04Yz5q3U7+qP3nWDH61Zgf3fuFsPnf3i5x36kT+WN25PMno8hKuOnsmja2JLkNo8+kTZ0zj0Vd2RWccxj44exLPberZkZ82ZWw5ew92/hiYO3N8R83olk/P5fdv1vDrNTuZf/KEHqPewnkBvn7Ru6jaVsuTr3UG5eev/whlxUU8tHpHx4+kj77rOFZvq+OHV87l7QNNzJk2lsWPvNaxftiu+iOcd8okRpYVsWH3ISZUlJFw562aw1SUlzCzsoKr/uMFTj1uNJfNnca4ijJuWvYm/3LJHCaOLuOzd70IwA+vOIOzTqhkc81hTphQQVNrgjVv1zFmRCnJpDN6RAnba5tobE0wbdwIykuLWLejgRMnVHDOyRNxh/qmVo60JSgtLmLS6HL2HmzmuLHlbDvQREt7gsqKMsaMKKGpNcGehmbqmlp5/ymTqCgrpuZQC9vrjvC/fvkK93z+fcydOZ5frt7Oxj2H+R9/fjIHj7RRXGTMqKygtNiob2pjZfV+RpYWM2faWMpKiigrLqK8pIiykiISSaexJcHB5jZGl5eQcKc94VSUFVNaXETDkTbMUj8MzYwX36rl+LEjePe0sWCpFSFGBuWC1Nyr9qQzsrSYkaXFjCovYVR53+oBZrba3edlPKZg0bv0zX7d/1nAl37+Mjf+1em9/tLZdqARwzhhYip4/M19q3n57XpOmFDBqrdqeenrH2XymHLaE0l21h/hxImppqCW9gRlxan/SKd+/Xd85J3Hcffn3wdAeyJJkVnHL7md9UcoNmN8RSmbaw5z8a0rmTtzPL+57rwe5en+y23WoscpLyni1ONGc9rxY/j1mp28+PXzOW7MCF7aWsvlP3meJV84m28/toFN+w7zxrcuZM22Ot5/6iQajrQxorSI+f+6nLrgl/z9fz2fc0+ZCMCPlm/iB8tSTUHHjSlnRGkxbwdNKJlc/J6pPL4uNZLonceP4Y09XZuWrj5vFvf8cSu/uHY+55w8kfZEklNjzn0pKy7qMhnvQ++YzJaaw0wcXR5rIl8cV86bSf2R1i43VZHBdvHpU7ntM2f16dxBCRZmdjdwCbDP3f8sSJsA/AKYBWwFrnD3OkvdzW4BLgKagM+7+5rgnIXAN4LLftvdl0S9dz6Dxb3Pb+XMmZWcPmNcZN582VxzmKnjRsReNfWh1TtY8O4pHau59iYcPNoSSQ4eaWPi6M5O9MMt7YwuL6G+qZUNuw7y/lN7LmGSSDoG1B9pY0KonyaRdHbUpYLDxNHljA5+3bS2J2lLJHluUw3nnjyJspIiHKeirISt+xvZXtfEaceP4cnX9nL5e2fw0tZaGlsSfGzOFFa8sY/z33VcR5lTTT1v0tyW5BNzp3Hp3GnctmIz80+aQCLYRGrerAkk3fnNyzs5bcoYzjqxssu8mQertvOeGeOorChj38EWqmsO8YkzplNkqQmCD7+8k7EjSqk/0srruw/yvlkTmH/yROqaWqlvamPuzPE8v/kA55w8oeM7emTtTqq21nHR6VM51NzGtgNNNBxp4/2nTGTKuBEsXbebdxw/hvKSImoOtTCjsoJVbx1g0uhy5s4cz4jSYk6eNIo/bT7A+l0NjBlRwgdPncxv1+1iwZwpTBhVxotv1XLKcaM53NJO7eFWGo600dSWYEblSDbsOsiMypG0tCU5efIozIyKsmKWvrqb0eUlOKk1vIrMaG5LcOYJlZSVFLH3YDOVFWWcdUIlT762h9Jio7E1waHmdiaMKmVXfTNjRpQwaXQ5bYkk+w61MLq8hPNOncSWmsO0JZxDzW20J53R5SUcaUsw78RKttc1sfdgC+2JJG0J58SJFVTvO0xdUxtnzBjHcWPLaU84SYd1O+ppaU8ydkQplaNKGTOihIamNirKSpgybkTHL+jaxhYMo7jIcGB7bRNr3q5j5oQK5kwdy4RRZUwbP5KnN+xl7MgSpo+vYNzIUhpb22lqaae2sZW2pDNxVBk764/QnvCOH07lpUUcaU1SUVZMfVMrZSXFlBYbh1vaGVFaTFsiyaHm1HN3Z0ZlBS3tCVrakoyrKKXhSBsNTW0UFRnjR5ZyuKWdA42tnDI5/WMwSWvwaE8mKSkqwoGxI0ooKymiPVjDrbk9wejyEspLikm44+4dqzW7O21BvvakM238CEaUFtPQ1Ja6RtJpDv4//MVpx8W4c/Q0WMHiQ8Bh4N5QsPgeUOvuN5rZIqDS3f+3mV0E/C2pYHEOcIu7nxMElypgHqlJvKuB97p75gH7gXwGCxGRY0VvwaJgo6Hc/Q9A9ynBlwLpmsES4LJQ+r2e8gIw3symAhcAy9y9NggQy4ALC1VmERHJbKCHzk5x9/R01z1Aesuz6UB4dbodQVq29B7M7FozqzKzqpqamvyWWkTkGDdo8yw81f6VtzYwd7/D3ee5+7zJk/M/k1pE5Fg20MFib9C8RPB3X5C+EwjPCJsRpGVLFxGRATTQweJRYGHwfCHwSCj9c5YyH2gImqueBBaYWaWZVQILgjQRERlABZvBbWb3A38BTDKzHcBi4EbgQTO7BtgGXBFkX0pqJFQ1qaGzVwO4e62ZfQt4Kcj3TXfPvo62iIgUhCbliYgIMEhDZ0VEZPgYljULM6sh1czVV5OA7AvxDD/H2ucFfeZjhT5zbk5094zDSYdlsOgvM6vKVhUbjo61zwv6zMcKfeb8UTOUiIhEUrAQEZFIChaZ3THYBRhgx9rnBX3mY4U+c56oz0JERCKpZiEiIpEULEREJJKCRYiZXWhmG82sOticaVgws5lmtsLMNpjZa2b25SB9gpktM7NNwd/KIN3M7Nbg32GdmfVtj8ZBZmbFZvaymT0WvD7JzFYFn+sXZlYWpJcHr6uD47MGs9z9YWbjzewhM3vDzF43s3OPge/5H4L/1+vN7H4zGzHcvmszu9vM9pnZ+lBazt+rmS0M8m8KdiGNTcEiYGbFwG3Ax4E5wFVmNmdwS5U37cA/ufscYD5wXfDZFgHL3X02sDx4Dal/g9nB41rg9oEvcl58GXg99Pq7wE3ufipQB1wTpF8D1AXpNwX5jla3AE+4+zuBM0h9/mH7PZvZdODvgHnBjpzFwKcZft/1/6Pnxm85fa/BzqOLSe1GejawOB1gYvFgn9dj/QGcCzwZen09cP1gl6tAn/UR4GPARmBqkDYV2Bg8/ylwVSh/R76j5UFqOfvlwEeAxwAjNau1pPv3TWol43OD5yVBPhvsz9CHzzwOeKt72Yf595zeIG1C8N09RmqHzWH3XQOzgPV9/V6Bq4CfhtK75It6qGbRKfaufEezoNp9JrCK3HcuPJrcDHwVSAavJwL17t4evA5/po7PGxxvCPIfbU4CaoB7gua3O81sFMP4e3b3ncC/AW8Du0l9d6sZ/t81FHDn0UwULI4hZjYa+BXw9+5+MHzMUz81hsU4ajO7BNjn7qsHuywDrAQ4C7jd3c8EGulsmgCG1/cMEDSjXEoqUE4DRtGzuWbYG4jvVcGi07Delc/MSkkFivvc/ddBcq47Fx4tzgM+YWZbgQdINUXdAow3s/QeLuHP1PF5g+PjgAMDWeA82QHscPdVweuHSAWP4fo9A3wUeMvda9y9Dfg1qe9/uH/XMMA7jypYdHoJmB2Moigj1Un26CCXKS/MzIC7gNfd/YehQ7nuXHhUcPfr3X2Gu88i9T0+4+6fAVYAnwqydf+86X+HTwX5j7pf3+6+B9huZqcFSecDGxim33PgbWC+mVUE/8/Tn3lYf9eBgd15dLA7bYbSg9RufW8Cm4GvD3Z58vi5PkCqiroOWBs8LiLVVrsc2AQ8DUwI8hupkWGbgVdJjTQZ9M/Rx8/+F8BjwfOTgRdJ7cj4S6A8SB8RvK4Ojp882OXux+edC1QF3/VvgMrh/j0D/xd4A1gP/CdQPty+a+B+Un0ybaRqkNf05XsFvhB89mrg6lzKoOU+REQkkpqhREQkkoKFiIhEUrAQEZFIChYiIhJJwUJERCIpWIgUkJn9vZlVDHY5RPpLQ2dFCiiYRT7P3fcPdllE+kM1C5E8MbNRZva4mb0S7K2wmNR6RSvMbEWQZ4GZPW9ma8zsl8F6XZjZVjP7npm9amYvmtmpg/lZRLpTsBDJnwuBXe5+hqf2VrgZ2AV82N0/bGaTgG8AH3X3s0jNtP7H0PkN7n468OPgXJEhQ8FCJH9eBT5mZt81sw+6e0O34/NJbaz1RzNbS2o9nxNDx+8P/T234KUVyUFJdBYRicPd3wy2sLwI+LaZLe+WxYBl7n5VtktkeS4y6FSzEMkTM5sGNLn7z4Dvk1oe/BAwJsjyAnBeuj8i6ON4R+gSV4b+Pj8wpRaJRzULkfw5Hfi+mSVJrQ76P0k1Jz1hZruCfovPA/ebWXlwzjdIrXQMUGlm64AWUltgigwZGjorMgRoiK0MdWqGEhGRSKpZiIhIJNUsREQkkoKFiIhEUrAQEZFIChYiIhJJwUJERCL9f4pJuJoPNX54AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYXNIcOzgcnB",
        "outputId": "301ecd75-d41f-4d8a-b172-ce4388a1792a"
      },
      "source": [
        "# output the learned variational parameters\n",
        "print(\"b0 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_mean_b0\").item(), pyro.param(\"guide_scale_b0\").item()))\n",
        "print(\"b1 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_mean_b1\").item(), pyro.param(\"guide_scale_b1\").item()))\n",
        "print(\"b2 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_mean_b2\").item(), pyro.param(\"guide_scale_b2\").item()))\n",
        "print(\"b3 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_mean_b3\").item(), pyro.param(\"guide_scale_b3\").item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b0 ~ Normal(0.2719, 0.0293)\n",
            "b1 ~ Normal(-0.0508, 0.0547)\n",
            "b2 ~ Normal(-1.1101, 0.1358)\n",
            "b3 ~ Normal(0.4091, 0.1761)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOzSqWatgcZq"
      },
      "source": [
        "class appraisalRegressionModule(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(appraisalRegressionModule, self).__init__()\n",
        "        self.linear = nn.Linear(num_features, 1)\n",
        "\n",
        "    def forward(self, outcome):\n",
        "        return self.linear(outcome)\n",
        "\n",
        "regression_model = appraisalRegressionModule(OUTCOME_VAR_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl1HpwW5gyn-"
      },
      "source": [
        "# emotion_data splice dimension\n",
        "\n",
        "# Happy           ->  OUTCOME_VAR_DIM\n",
        "# Sad             ->  OUTCOME_VAR_DIM + 1\n",
        "# Anger           ->  OUTCOME_VAR_DIM + 2\n",
        "# Disgust         ->  OUTCOME_VAR_DIM + 3\n",
        "# Fear            ->  OUTCOME_VAR_DIM + 4\n",
        "# Content         ->  OUTCOME_VAR_DIM + 5\n",
        "# Disappointment  ->  OUTCOME_VAR_DIM + 6\n",
        "\n",
        "def bayesianRegressionModel(data):\n",
        "    # Create unit normal priors over the parameters\n",
        "    weights_loc   = torch.zeros(size=(torch.Size((1, OUTCOME_VAR_DIM))))\n",
        "    weights_scale = torch.ones(size=(torch.Size((1, OUTCOME_VAR_DIM))))\n",
        "    weights_prior = Normal(weights_loc, weights_scale).independent(1)\n",
        "    \n",
        "    # location and scale prior for the bias\n",
        "    bias_loc   = torch.zeros(size=(torch.Size((1, ))))\n",
        "    bias_scale = torch.ones(size=(torch.Size((1, ))))\n",
        "    bias_prior = Normal(bias_loc, bias_scale).independent(1)\n",
        "    \n",
        "    priors = {'linear.weight': weights_prior, 'linear.bias': bias_prior}\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", regression_model, priors)\n",
        "    # sample a model (which also samples from weights_prior and bias_prior)\n",
        "    sampled_regression_model = lifted_module()\n",
        "    \n",
        "    with pyro.plate(\"map\"):\n",
        "        outcome_data = data[:, :(OUTCOME_VAR_DIM)]\n",
        "        # Here, for simplification, we are only taking one emotion variable (happy)\n",
        "        # instead of all 8 emotions\n",
        "        # OUTCOME_VAR_DIM = 8 = Happy (Change the number accordingly for subsequent emotions)\n",
        "        emotion_data = data[:, OUTCOME_VAR_DIM + 6]  \n",
        "        \n",
        "        # run the regressor forward conditioned on data\n",
        "        prediction = sampled_regression_model(outcome_data).squeeze(-1)\n",
        "        # condition on the observed data\n",
        "        pyro.sample(\"obs\", Normal(prediction, 1), obs = emotion_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HraerY9egyjo"
      },
      "source": [
        "def bayesianRegressionGuide(data):\n",
        "    # define our variational parameters\n",
        "    weights_loc   = torch.randn(1, OUTCOME_VAR_DIM)\n",
        "    # Note that the scale has to be non-negative. Thus, we use exp() to get a non-negative number.\n",
        "    # we also use a narrower scale (exp(-1) ~ 0.35 instead of exp(0) = 1)\n",
        "    weights_scale = torch.exp(-1.0 * torch.ones(1, OUTCOME_VAR_DIM) + 0.05 * torch.randn(1, OUTCOME_VAR_DIM))\n",
        "    bias_loc      = torch.randn(1)\n",
        "    bias_scale    = torch.exp(-1.0 * torch.ones(1) + 0.05 * torch.randn(1))\n",
        "\n",
        "    # using pyro.param() to register the variational parameters\n",
        "    weight_loc_param   = pyro.param(\"guide_loc_weight\", weights_loc)\n",
        "    weight_scale_param = pyro.param(\"guide_scale_weight\", weights_scale)\n",
        "    bias_loc_param     = pyro.param(\"guide_loc_bias\", bias_loc)\n",
        "    bias_scale_param   = pyro.param(\"guide_scale_bias\", bias_scale)\n",
        "    # guide distributions for w and b\n",
        "    weight_dist = Normal(weight_loc_param, weight_scale_param).independent(1)\n",
        "    bias_dist   = Normal(bias_loc_param, bias_scale_param).independent(1)\n",
        "    dists = {'linear.weight': weight_dist, 'linear.bias': bias_dist}\n",
        "    # lift the module and sample from that distribution\n",
        "    lifted_module = pyro.random_module(\"module\", regression_model, dists)\n",
        "    return lifted_module()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "axafP06UgyhT",
        "outputId": "86c2d304-5177-4d22-b716-36ee2b0e3a48"
      },
      "source": [
        "pyro.clear_param_store()\n",
        "\n",
        "num_iterations = 1000\n",
        "\n",
        "# setup the optimizer with some learning rate\n",
        "optimizer = Adam({\"lr\": 0.005})\n",
        "\n",
        "# setup the inference algorithm\n",
        "bayesianRegressionSVI = SVI(bayesianRegressionModel, bayesianRegressionGuide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "# Splitting into training and testing datasets\n",
        "# train_size = int(0.75 * len(outcome_emotion_dataset))\n",
        "# test_size = len(outcome_emotion_dataset) - train_size\n",
        "# train_dataset, test_dataset = torch.utils.data.random_split(outcome_emotion_dataset, [train_size, test_size])\n",
        "\n",
        "# do gradient steps\n",
        "losses = []\n",
        "for thisIteration in range(num_iterations):\n",
        "    # calculate the loss and take a gradient step\n",
        "    thisLoss = bayesianRegressionSVI.step(train_set)\n",
        "    losses.append(thisLoss)\n",
        "    if thisIteration % 100 == 0:\n",
        "        print(\"[iteration %04d] loss: %.4f\" % (thisIteration + 1, thisLoss / float(N_samples)))\n",
        "        \n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(\"ELBO\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iteration 0001] loss: 2.5498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:492: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iteration 0101] loss: 1.0786\n",
            "[iteration 0201] loss: 1.0699\n",
            "[iteration 0301] loss: 1.0650\n",
            "[iteration 0401] loss: 1.0369\n",
            "[iteration 0501] loss: 1.0227\n",
            "[iteration 0601] loss: 1.0148\n",
            "[iteration 0701] loss: 1.0090\n",
            "[iteration 0801] loss: 0.9948\n",
            "[iteration 0901] loss: 1.0003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 212
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqT9sRDcgyfG",
        "outputId": "7cdbb3e2-687f-4132-a660-776cc30ba079"
      },
      "source": [
        "#for name in pyro.get_param_store().get_all_param_names():\n",
        "#    print(name, pyro.param(name).data.numpy())\n",
        "\n",
        "guide_loc_weight = pyro.param(\"guide_loc_weight\")[0]\n",
        "guide_scale_weight = pyro.param(\"guide_scale_weight\")[0]\n",
        "\n",
        "print(\"b0 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_loc_bias\").item(), pyro.param(\"guide_scale_bias\").item()))\n",
        "for j in range(len(guide_loc_weight)):\n",
        "    print(\"b%1d\" % (j+1), \"~ Normal(%.4f, %.4f)\" % (guide_loc_weight[j], guide_scale_weight[j]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b0 ~ Normal(-0.7716, 0.0259)\n",
            "b1 ~ Normal(-0.3039, 0.0968)\n",
            "b2 ~ Normal(0.9158, 0.0564)\n",
            "b3 ~ Normal(1.2147, 0.0416)\n",
            "b4 ~ Normal(1.1157, 0.0799)\n",
            "b5 ~ Normal(-0.9618, 0.0846)\n",
            "b6 ~ Normal(-0.0373, 0.1022)\n",
            "b7 ~ Normal(-1.1585, 0.0398)\n",
            "b8 ~ Normal(0.1713, 0.0694)\n",
            "b9 ~ Normal(0.1973, 0.0544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNGaAmbXhVGj"
      },
      "source": [
        "b_0 = pyro.sample(\"b_0\", Normal(pyro.param(\"guide_loc_bias\").item(), pyro.param(\"guide_scale_bias\").item()))\n",
        "b_1 = pyro.sample(\"b_1\", Normal(guide_loc_weight[0], guide_scale_weight[0]))\n",
        "b_2 = pyro.sample(\"b_2\", Normal(guide_loc_weight[1], guide_scale_weight[1]))\n",
        "b_3 = pyro.sample(\"b_3\", Normal(guide_loc_weight[2], guide_scale_weight[2]))\n",
        "b_4 = pyro.sample(\"b_4\", Normal(guide_loc_weight[3], guide_scale_weight[3]))\n",
        "b_5 = pyro.sample(\"b_5\", Normal(guide_loc_weight[4], guide_scale_weight[4]))\n",
        "b_6 = pyro.sample(\"b_6\", Normal(guide_loc_weight[5], guide_scale_weight[5]))\n",
        "b_7 = pyro.sample(\"b_7\", Normal(guide_loc_weight[6], guide_scale_weight[6]))\n",
        "b_8 = pyro.sample(\"b_8\", Normal(guide_loc_weight[7], guide_scale_weight[7]))\n",
        "b_9 = pyro.sample(\"b_9\", Normal(guide_loc_weight[8], guide_scale_weight[8]))\n",
        "# print(b_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf2GFG2apeZn"
      },
      "source": [
        "# print(sampled_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhcbOFhEhdUY"
      },
      "source": [
        "# new_data = [0.20,    0.60,     0.90,   0.33,   0.20,   0.47,  0.90,     0.47,      0.960]\n",
        "\n",
        "new_predictions = []\n",
        "for new_data in test_set:\n",
        "  # print(\"New Data 9 : \", new_data[9])\n",
        "  new_prediction = b_0 + b_1 * new_data[0] + b_2 * new_data[1] + b_3 * new_data[2] + b_4 * new_data[3] + b_5 * new_data[4] + b_6 * new_data[5] + b_7 * new_data[6] + b_8 * new_data[7] + b_9 * new_data[8] \n",
        "  new_predictions.append(new_prediction.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovQgA6MzpSpm",
        "outputId": "2acee493-e1b5-4e97-f1a9-5296e46b024a"
      },
      "source": [
        "# Dimension value for test_set to calculate average_MAE\n",
        "\n",
        "# Happy           ->  9\n",
        "# Sad             ->  10\n",
        "# Anger           ->  11\n",
        "# Disgust         ->  12\n",
        "# Fear            ->  13\n",
        "# Content         ->  14\n",
        "# Disappointment  ->  15\n",
        "\n",
        "import math\n",
        "\n",
        "average_rmse = 0\n",
        "for x in range(len(test_set)):\n",
        "  average_rmse += math.sqrt(abs((math.pow(new_predictions[x], 2) - math.pow(test_set[x][15].item(), 2))))\n",
        "  # print(math.sqrt(abs((math.pow(new_predictions[x], 2) - math.pow(test_dataset.dataset[x][9].item(), 2)))))\n",
        "\n",
        "average_rmse = average_rmse/len(test_set)\n",
        "\n",
        "print(average_rmse)\n",
        "# average_MAE = average_MAE/5\n",
        "\n",
        "# print(average_MAE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.38958410243688857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PELAuvwChD9Y"
      },
      "source": [
        "# ------------------------------------------------- Multiple Emotions [Proposed EMPath Framework] ------------------------------------\n",
        "# ---------------------------------------------------------------------------------------------------------------------------------\n",
        "# ---------------------------------------------------------------------------------------------------------------------------------\n",
        "# ---------------------------------------------------------------------------------------------------------------------------------\n",
        "# ---------------------------------------------------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Elzdw9Rf1pi",
        "outputId": "4a4a6db3-e873-49da-ebcc-9329e57b0d8d"
      },
      "source": [
        "!pip install torch torchvision pyro-ppl\n",
        "\n",
        "#import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.model_selection as sk\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.distributions import Normal\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "print(\"Currently using Pyro version: \" + pyro.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (0.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (4.62.3)\n",
            "Currently using Pyro version: 1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWw2weqMf1k2",
        "outputId": "22de31b1-9e24-4be6-b9cf-74bb9e5e3aa0"
      },
      "source": [
        "# data location\n",
        "#dataset_path = os.path.join(os.path.abspath('..'), \"CognitionData\", \"data_wheelOnly.csv\")\n",
        "dataset_path = \"https://desmond-ong.github.io/pplAffComp/CognitionData/data_wheelOnly.csv\"\n",
        "\n",
        "OUTCOME_VAR_NAMES = [\"payoff1\", \"payoff2\", \"payoff3\", \"prob1\", \"prob2\", \"prob3\", \"win\", \"winProb\", \"angleProp\"]\n",
        "EMOTION_VAR_NAMES = [\"happy\", \"sad\", \"anger\", \"disgust\", \"fear\", \"content\", \"disapp\"]\n",
        "\n",
        "OUTCOME_VAR_NAMES_CONV = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "EMOTION_VAR_NAMES_CONV = [9, 10, 11, 12, 13, 14, 15]\n",
        "\n",
        "OUTCOME_VAR_DIM = len(OUTCOME_VAR_NAMES)\n",
        "EMOTION_VAR_DIM = len(EMOTION_VAR_NAMES)\n",
        "\n",
        "def load_outcome_emotion_dataset(csv_file, normalize_values=True, preview_datafile=False):\n",
        "    data_readin = pd.read_csv(csv_file)\n",
        "    outcome_data = data_readin.loc[:,OUTCOME_VAR_NAMES]\n",
        "    if normalize_values:\n",
        "        ####\n",
        "        ## payoff1, payoff2, payoff3 and win are between 0 and 100\n",
        "        ## need to normalize to [0,1] to match the rest of the variables,\n",
        "        ## by dividing payoff1, payoff2, payoff3 and win by 100\n",
        "        ####\n",
        "        outcome_data.loc[:,\"payoff1\"] = outcome_data.loc[:,\"payoff1\"]/100\n",
        "        outcome_data.loc[:,\"payoff2\"] = outcome_data.loc[:,\"payoff2\"]/100\n",
        "        outcome_data.loc[:,\"payoff3\"] = outcome_data.loc[:,\"payoff3\"]/100\n",
        "        outcome_data.loc[:,\"win\"]     = outcome_data.loc[:,\"win\"]/100\n",
        "    outcome_data_tensor = torch.tensor(outcome_data.values).type(torch.Tensor)\n",
        "    \n",
        "    emotion_data = data_readin.loc[:,EMOTION_VAR_NAMES]\n",
        "    if normalize_values:\n",
        "        ## note that emotions are transformed from a 9 point Likert to [0,1] via emo <- (emo-1)/8\n",
        "        emotion_data   = (emotion_data-1)/8\n",
        "    emotion_data_tensor = torch.tensor(emotion_data.values).type(torch.Tensor)\n",
        "    \n",
        "    if preview_datafile:\n",
        "        print(\"Preview of first 3 rows:\")\n",
        "        print(outcome_data.loc[0:2,:])\n",
        "        print(emotion_data.loc[0:2,:])\n",
        "    \n",
        "    data = torch.cat((outcome_data_tensor, emotion_data_tensor), 1)\n",
        "\n",
        "    preprocessed_data = pd.concat([outcome_data, emotion_data], axis=1)\n",
        "\n",
        "    shuffled_data = preprocessed_data.sample(frac=1)\n",
        "    divided_parts = np.array_split(shuffled_data, 4)  \n",
        "\n",
        "    train_set = pd.concat([divided_parts[0], divided_parts[1]], axis = 0)\n",
        "    train_set = pd.concat([train_set, divided_parts[2]], axis = 0)\n",
        "    test_set  = divided_parts[3] \n",
        "    \n",
        "    # train_set_tensor = torch.tensor(train_set.values).type(torch.Tensor)\n",
        "    # test_set_tensor  = torch.tensor(test_set.values).type(torch.Tensor)\n",
        "    \n",
        "    # return train_set, test_set\n",
        "    # for part in result:\n",
        "      # print(part,'\\n')\n",
        "    # X_train, X_test, Y_train, Y_test = sk.train_test_split(OUTCOME_VAR_NAMES,EMOTION_VAR_NAMES,test_size=0.25, random_state = 42)\n",
        "\n",
        "    # print(\"X_train : \", X_train)\n",
        "    # return data    \n",
        "    # # Splitting into training and testing datasets\n",
        "    # train_size = int(0.75 * len(data))\n",
        "    # test_size = len(data) - train_size\n",
        "    # train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])\n",
        "\n",
        "    # print(len(data))\n",
        "    # print(len(train_dataset.dataset))\n",
        "    # print(len(test_dataset.dataset))\n",
        "\n",
        "    # train_dataset_pd = pd.DataFrame(train_dataset.dataset).astype(\"float\")\n",
        "    # test_dataset_pd = pd.DataFrame(test_dataset.dataset).astype(\"float\")\n",
        "\n",
        "    # # print(train_data)\n",
        "    outcome_data_train =  train_set.loc[:,OUTCOME_VAR_NAMES]\n",
        "    emotion_data_train = train_set.loc[:,EMOTION_VAR_NAMES]\n",
        "    outcome_data_test = test_set.loc[:,OUTCOME_VAR_NAMES]\n",
        "    emotion_data_test = test_set.loc[:,EMOTION_VAR_NAMES]\n",
        "\n",
        "    # # return data\n",
        "    return outcome_data_train, emotion_data_train, outcome_data_test, emotion_data_test\n",
        "\n",
        "# reads in datafile.\n",
        "print(\"Reading in dataset...\")\n",
        "# train_set, test_set = load_outcome_emotion_dataset(csv_file=dataset_path, preview_datafile=True)\n",
        "outcome_data_train, emotion_data_train, outcome_data_test, emotion_data_test = load_outcome_emotion_dataset(csv_file=dataset_path, preview_datafile=True)\n",
        "\n",
        "\n",
        "# Splitting into training and testing datasets\n",
        "# train_size = int(0.75 * len(outcome_emotion_dataset))\n",
        "# test_size = len(outcome_emotion_dataset) - train_size\n",
        "# train_dataset, test_dataset = torch.utils.data.random_split(outcome_emotion_dataset, [train_size, test_size])\n",
        "\n",
        "# print(len(outcome_emotion_dataset))\n",
        "# print(len(train_dataset.dataset))\n",
        "# print(len(test_dataset.dataset))\n",
        "\n",
        "# train_dataset_pd = pd.DataFrame(train_dataset.dataset).astype(\"float\")\n",
        "# test_dataset_pd = pd.DataFrame(test_dataset.dataset).astype(\"float\")\n",
        "\n",
        "# # print(train_data)\n",
        "# outcome_data_train =  train_dataset_pd.loc[:,OUTCOME_VAR_NAMES_CONV]\n",
        "# emotion_data_train = train_dataset_pd.loc[:,EMOTION_VAR_NAMES_CONV]\n",
        "# outcome_data_test = test_dataset_pd.loc[:,OUTCOME_VAR_NAMES_CONV]\n",
        "# emotion_data_test = test_dataset_pd.loc[:,EMOTION_VAR_NAMES_CONV]\n",
        "\n",
        "\n",
        "print(train_set)\n",
        "# outcome_data = outcome_emotion_dataset[:, :(OUTCOME_VAR_DIM)]\n",
        "# emotion_data = outcome_emotion_dataset[:, (OUTCOME_VAR_DIM):]\n",
        "\n",
        "print(\"Outcome Train Set Shape : \", outcome_data_train.shape)\n",
        "print(\"Emotion Train Set Shape : \", emotion_data_train.shape)\n",
        "print(\"Outcome Test Set Shape : \", outcome_data_test.shape)\n",
        "print(\"Emotion Test Set Shape : \", emotion_data_test.shape)\n",
        "\n",
        "# N_samples = outcome_emotion_dataset.shape[0]\n",
        "\n",
        "# print(\"Shape of dataset: \", outcome_emotion_dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading in dataset...\n",
            "Preview of first 3 rows:\n",
            "   payoff1  payoff2  payoff3  prob1  prob2  prob3  win  winProb  angleProp\n",
            "0     0.50     0.75      0.9   0.30   0.52   0.18  0.5     0.30      0.921\n",
            "1     0.15     0.70      0.8   0.45   0.29   0.26  0.8     0.26      0.873\n",
            "2     0.50     0.75      0.9   0.30   0.52   0.18  0.5     0.30      0.467\n",
            "   happy    sad  anger  disgust  fear  content  disapp\n",
            "0  0.625  0.000  0.000     0.25   0.0    0.625   0.375\n",
            "1  0.875  0.000  0.000     0.00   0.0    0.000   0.000\n",
            "2  0.625  0.125  0.125     0.00   0.0    0.250   0.500\n",
            "tensor([[0.2000, 0.4500, 0.7000,  ..., 0.1250, 0.8750, 0.1250],\n",
            "        [0.5000, 0.7500, 0.9000,  ..., 0.0000, 0.0000, 0.3750],\n",
            "        [0.2500, 0.6000, 1.0000,  ..., 0.3750, 0.5000, 0.6250],\n",
            "        ...,\n",
            "        [0.2000, 0.6000, 0.9000,  ..., 0.0000, 0.8750, 0.0000],\n",
            "        [0.2000, 0.6000, 0.9000,  ..., 0.1250, 0.7500, 0.0000],\n",
            "        [0.5000, 0.7500, 0.9000,  ..., 0.0000, 0.3750, 0.0000]])\n",
            "Outcome Train Set Shape :  (1156, 9)\n",
            "Emotion Train Set Shape :  (1156, 7)\n",
            "Outcome Test Set Shape :  (385, 9)\n",
            "Emotion Test Set Shape :  (385, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1q6zREZcRoW"
      },
      "source": [
        "# sampled_data = outcome_data.loc[0:10, :]\n",
        "# print(sampled_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdUWsCShk3-t"
      },
      "source": [
        "# sampled_target = emotion_data.loc[0:10, :]\n",
        "# print(sampled_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5guv-l9f1hu"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from numpy import asarray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yLc5OSGf1dg"
      },
      "source": [
        "def get_model(n_inputs, n_outputs):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(320, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(160, input_dim=320, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(80, input_dim=160, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(40, input_dim=80, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(n_outputs))\n",
        "  model.compile(loss='mae', optimizer='adam')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCDKo-tSgGXm"
      },
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "from numpy import mean\n",
        "from numpy import std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04lHZotQf1Y6"
      },
      "source": [
        "def evaluate_model(X, y):\n",
        "\tresults = list()\n",
        "\tn_inputs, n_outputs = X.shape[1], y.shape[1]\n",
        "\t# define evaluation procedure\n",
        "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\t# enumerate folds\n",
        "\tfor train_ix, test_ix in cv.split(X):\n",
        "\t\t# prepare data\n",
        "    # x.iloc[list(train_index)], x.iloc[list(test_index)]\n",
        "\t\tX_train, X_test = X.iloc[list(train_ix)], X.iloc[list(test_ix)]\n",
        "\t\ty_train, y_test = y.iloc[list(train_ix)], y.iloc[list(test_ix)]\n",
        "\t\t# define model\n",
        "\t\tmodel = get_model(n_inputs, n_outputs)\n",
        "\t\t# fit modelb\n",
        "\t\tmodel.fit(X_train, y_train, verbose=0, epochs=100)\n",
        "\t\t# evaluate model on test set\n",
        "\t\tmae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\t\t# store result\n",
        "\t\tprint('>%.3f' % mae)\n",
        "\t\tresults.append(mae)\n",
        "\treturn results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvPCGx6Ennhp"
      },
      "source": [
        "# print(\"Outcome Data\")\n",
        "# print(outcome_data)\n",
        "# print(outcome_data.shape)\n",
        "\n",
        "# print(\"Emotion Data\")\n",
        "# print(emotion_data)\n",
        "# print(emotion_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aMET174f1UL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca94bc4-5dde-427f-e4f7-471709e8442d"
      },
      "source": [
        "# evaluate model\n",
        "results = evaluate_model(outcome_data_train, emotion_data_train)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">0.148\n",
            ">0.126\n",
            ">0.136\n",
            ">0.132\n",
            ">0.150\n",
            ">0.137\n",
            ">0.125\n",
            ">0.132\n",
            ">0.139\n",
            ">0.125\n",
            ">0.135\n",
            ">0.140\n",
            ">0.146\n",
            ">0.141\n",
            ">0.129\n",
            ">0.135\n",
            ">0.135\n",
            ">0.132\n",
            ">0.128\n",
            ">0.124\n",
            ">0.139\n",
            ">0.124\n",
            ">0.140\n",
            ">0.148\n",
            ">0.137\n",
            ">0.130\n",
            ">0.135\n",
            ">0.130\n",
            ">0.128\n",
            ">0.137\n",
            "MAE: 0.135 (0.007)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHvYAm9of1SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d7d31c-1ad0-42a2-9fc2-f0050e6caee9"
      },
      "source": [
        "n_inputs, n_outputs = outcome_data_train.shape[1], emotion_data_train.shape[1]\n",
        "# get model\n",
        "model = get_model(n_inputs, n_outputs)\n",
        "# fit the model on all data\n",
        "model.fit(outcome_data_train, emotion_data_train, verbose=0, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f271df87090>"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqF35ombNhXd"
      },
      "source": [
        "def mood_push_and_pull(VEC_PAD, CurrentMood_PAD, push_intensity):\n",
        "  \n",
        "  dist_between_VEC_Current  = math.sqrt(math.pow(VEC_P - CurrentMood_PAD[0], 2) + math.pow(VEC_A - CurrentMood_PAD[1], 2) + math.pow(VEC_D - CurrentMood_PAD[2], 2))\n",
        "  scale = push_intensity/dist_between_VEC_Current\n",
        "\n",
        "  if (((VEC_PAD[0] * CurrentMood_PAD[0]) > 0) and ((VEC_PAD[1] * CurrentMood_PAD[1]) > 0) and ((VEC_PAD[2] * CurrentMood_PAD[2]) > 0) ):\n",
        "    if (VEC_PAD[0] >= 0):\n",
        "      if (CurrentMood_PAD[0] < VEC_PAD[0]):\n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (VEC_PAD[0] - CurrentMood_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (VEC_PAD[1] - CurrentMood_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (VEC_PAD[2] - CurrentMood_PAD[2]))\n",
        "      else:\n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (CurrentMood_PAD[0] - VEC_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (CurrentMood_PAD[1] - VEC_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (CurrentMood_PAD[2] - VEC_PAD[2]))\n",
        "    else:\n",
        "      if (CurrentMood_PAD[0] > VEC_PAD[0]):\n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (VEC_PAD[0] - CurrentMood_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (VEC_PAD[1] - CurrentMood_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (VEC_PAD[2] - CurrentMood_PAD[2]))\n",
        "      else:\n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (CurrentMood_PAD[0] - VEC_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (CurrentMood_PAD[1] - VEC_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (CurrentMood_PAD[2] - VEC_PAD[2]))\n",
        "  else :   \n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (VEC_PAD[0] - CurrentMood_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (VEC_PAD[1] - CurrentMood_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (VEC_PAD[2] - CurrentMood_PAD[2]))\n",
        "\n",
        "  NewMood_PAD = [NewMood_P, NewMood_A, NewMood_D]\n",
        "  return NewMood_PAD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ3FTc-7LIbZ"
      },
      "source": [
        "# Concatenating Prediction + EMP Cycle in One Cell for looped predictions\n",
        "# print(outcome_data_test)\n",
        "outcome_data_test_arr = np.asarray(outcome_data_test)\n",
        "emotion_data_test_arr = np.asarray(emotion_data_test)\n",
        "\n",
        "final_emp_outcomes = []\n",
        "\n",
        "for target in outcome_data_test_arr:\n",
        "  # print(target)\n",
        "  newTarget = asarray([target])\n",
        "  yhat = model.predict(newTarget)\n",
        "  prediction = yhat[0]\n",
        "  # print('Predicted: %s' % yhat[0])\n",
        "\n",
        "  # Defining a character's personality based on the Big Five Personality Model\n",
        "  Openness = 0.4\n",
        "  Conscientiousness = 0.8\n",
        "  Extraversion = 0.6\n",
        "  Agreeableness = 0.3\n",
        "  Neuroticism = 0.4\n",
        "\n",
        "  # Since, we do not have information about the participants in the trial. We assume that on an average the peope were in a slightly relaxed default mood.\n",
        "  # The personality traits chosen are hence so. \n",
        "\n",
        "  # Calculating default mood in the PAD space based on the above peronality characteristics\n",
        "  Pleasure  = (0.21 * Extraversion) + (0.59 * Agreeableness)        + (0.19 * Neuroticism)\n",
        "  Arousal   = (0.15 * Openness)     + (0.30 * Agreeableness)        - (0.57 * Neuroticism)\n",
        "  Dominance = (0.25 * Openness)     + (0.17 * Conscientiousness)    + (0.60 * Extraversion)     - (0.32 * Agreeableness) \n",
        "\n",
        "  DefaultMood_PAD = [Pleasure, Arousal, Dominance]\n",
        "\n",
        "\n",
        "  # PAD Mappings for Emotions\n",
        "  # Mappings were not available for all emotions in the dataset. The emotions which were nearest in meaning and had mappings available were thus chosen.\n",
        "  # Except Surprise, we could find alternatives for every other emotion. As a result Surprise was dropped from the dataset and thus the predictions.\n",
        "\n",
        "  # Emotion (Dataset) <-------> Mapped Emotion in PAD Space\n",
        "  # Happy             -         Joy\n",
        "  # Sad               -         Remorse\n",
        "  # Anger             -         Anger\n",
        "  # Disgust           -         Shame\n",
        "  # Fear              -         Fear\n",
        "  # Content           -         Gratification\n",
        "  # Disappointment    -         Disappointment\n",
        "\n",
        "  Happy_Intensity              = prediction[0] if (prediction[0] > 0) else 0.0\n",
        "  Sad_Intensity                = prediction[1] if (prediction[1] > 0) else 0.0\n",
        "  Anger_Intensity              = prediction[2] if (prediction[2] > 0) else 0.0\n",
        "  Disgust_Intensity            = prediction[3] if (prediction[3] > 0) else 0.0\n",
        "  Fear_Intensity               = prediction[4] if (prediction[4] > 0) else 0.0\n",
        "  Content_Intensity            = prediction[5] if (prediction[5] > 0) else 0.0\n",
        "  Disappointment_Intensity     = prediction[6] if (prediction[6] > 0) else 0.0\n",
        "\n",
        "  Happy_PAD           = [0.4, 0.2, -0.3]\n",
        "  Sad_PAD             = [-0.3, 0.1, -0.6]\n",
        "  Anger_PAD           = [-0.51, 0.59, 0.25]\n",
        "  Disgust_PAD         = [-0.3, 0.1, -0.6]\n",
        "  Fear_PAD            = [-0.64, 0.60, -0.43]\n",
        "  Content_PAD         = [0.6, 0.5, 0.4]\n",
        "  Disappointment_PAD  = [-0.3, 0.1, -0.4]\n",
        "\n",
        "  Appraised_Intensities = [Happy_Intensity, Sad_Intensity, Anger_Intensity, Disgust_Intensity, Fear_Intensity, Content_Intensity, Disappointment_Intensity]\n",
        "  Mapped_Emotions       = [Happy_PAD, Sad_PAD, Anger_PAD, Disgust_PAD, Fear_PAD, Content_PAD, Disappointment_PAD]\n",
        "\n",
        "  # Calculating Virtual Emotion Centre\n",
        "  Summation_Intensities = Happy_Intensity + Sad_Intensity + Anger_Intensity + Disgust_Intensity + Fear_Intensity + Content_Intensity + Disappointment_Intensity\n",
        "\n",
        "  VEC_P   = ( (Happy_Intensity * Happy_PAD[0]) + (Sad_Intensity * Sad_PAD[0]) + (Anger_Intensity * Anger_PAD[0]) + (Disgust_Intensity * Disgust_PAD[0]) + (Fear_Intensity * Fear_PAD[0]) + (Content_Intensity * Content_PAD[0]) + (Disappointment_Intensity * Disappointment_PAD[0])) / Summation_Intensities\n",
        "  VEC_A   = ( (Happy_Intensity * Happy_PAD[1]) + (Sad_Intensity * Sad_PAD[1]) + (Anger_Intensity * Anger_PAD[1]) + (Disgust_Intensity * Disgust_PAD[1]) + (Fear_Intensity * Fear_PAD[1]) + (Content_Intensity * Content_PAD[1]) + (Disappointment_Intensity * Disappointment_PAD[1])) / Summation_Intensities\n",
        "  VEC_D   = ( (Happy_Intensity * Happy_PAD[2]) + (Sad_Intensity * Sad_PAD[2]) + (Anger_Intensity * Anger_PAD[2]) + (Disgust_Intensity * Disgust_PAD[2]) + (Fear_Intensity * Fear_PAD[2]) + (Content_Intensity * Content_PAD[2]) + (Disappointment_Intensity * Disappointment_PAD[2])) / Summation_Intensities\n",
        "\n",
        "  VEC_PAD = [VEC_P, VEC_A, VEC_D]\n",
        "  # print(\"Virtual Emotion Centre : \", VEC_PAD)\n",
        "\n",
        "  CurrentMood_PAD = DefaultMood_PAD\n",
        "  push_intensity = Summation_Intensities/7.0\n",
        "  NewMood_PAD = mood_push_and_pull(VEC_PAD, CurrentMood_PAD, push_intensity)\n",
        "\n",
        "  # Per Emotion Regulation \n",
        "  # P_Val = 1 if (Happy_PAD[0] * NewMood_PAD[0]) > 0 else -1\n",
        "  # A_Val = 1 if (Happy_PAD[1] * NewMood_PAD[1]) > 0 else -1\n",
        "  # D_Val = 1 if (Happy_PAD[2] * NewMood_PAD[2]) > 0 else -1\n",
        "\n",
        "  # New_Happy_P = Happy_PAD[0] * (1 + (0.25 * P_Val * NewMood_PAD[0]))\n",
        "  # New_Happy_A = Happy_PAD[1] * (1 + (0.25 * A_Val * NewMood_PAD[1]))\n",
        "  # New_Happy_D = Happy_PAD[2] * (1 + (0.25 * D_Val * NewMood_PAD[2]))\n",
        "\n",
        "  # New_Happy_PAD = [New_Happy_P, New_Happy_A, New_Happy_D]\n",
        "\n",
        "\n",
        "  # All emotions are regulated based on the valence value\n",
        "  New_Generated_Emotions = []\n",
        "\n",
        "  for emotion in Mapped_Emotions:\n",
        "    P_Val = 1 if (emotion[0] * NewMood_PAD[0]) > 0 else -1\n",
        "    A_Val = 1 if (emotion[1] * NewMood_PAD[1]) > 0 else -1\n",
        "    D_Val = 1 if (emotion[2] * NewMood_PAD[2]) > 0 else -1\n",
        "\n",
        "    New_Emotion_P = emotion[0] * (1 + (0.25 * P_Val * NewMood_PAD[0]))\n",
        "    New_Emotion_A = emotion[1] * (1 + (0.25 * A_Val * NewMood_PAD[1]))\n",
        "    New_Emotion_D = emotion[2] * (1 + (0.25 * D_Val * NewMood_PAD[2]))\n",
        "\n",
        "    New_Emotion_PAD = [New_Emotion_P, New_Emotion_A, New_Emotion_D]\n",
        "    New_Generated_Emotions.append(New_Emotion_PAD)\n",
        "  \n",
        "  Final_Intensities_Generated = []\n",
        "\n",
        "  Original_Emotion_Norms = []\n",
        "  New_Emotion_Norms =[]\n",
        "\n",
        "  # Calculating Norm for Original PADs \n",
        "  for emotion in Mapped_Emotions:\n",
        "    emotion_norm = math.sqrt(math.pow(emotion[0], 2) + math.pow(emotion[1], 2) + math.pow(emotion[2], 2))\n",
        "    Original_Emotion_Norms.append(emotion_norm)\n",
        "\n",
        "  # Calculating Norm for Newly Generated PADs \n",
        "  for new_emotion in New_Generated_Emotions:\n",
        "    new_emotion_norm  = math.sqrt(math.pow(new_emotion[0], 2) + math.pow(new_emotion[1], 2) + math.pow(new_emotion[2], 2))\n",
        "    New_Emotion_Norms.append(new_emotion_norm) \n",
        "\n",
        "  # Scaling Appraised Intensities to give final emotion values\n",
        "  for i in range(len(New_Emotion_Norms)):\n",
        "    final_emotion_intensity = (New_Emotion_Norms[i] * Appraised_Intensities[i])/Original_Emotion_Norms[i]\n",
        "    Final_Intensities_Generated.append(final_emotion_intensity)  \n",
        "  \n",
        "  final_emp_outcomes.append(Final_Intensities_Generated)\n",
        "  # print(\"Final Emotion Intensities Generated : \")\n",
        "  # print(Final_Intensities_Generated)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8xGkTo9PZ9E",
        "outputId": "72774470-dc5e-4310-f056-86b26d533d54"
      },
      "source": [
        "average_MAE = 0\n",
        "\n",
        "# Dimension value to calculate average_MAE\n",
        "\n",
        "# Happy           : 0\n",
        "# Sad             : 1\n",
        "# Anger           : 2\n",
        "# Disgust         : 3\n",
        "# Fear            : 4\n",
        "# Content         : 5\n",
        "# Disappointment  : 6\n",
        "\n",
        "for x in range(len(final_emp_outcomes)):\n",
        "  average_MAE += abs(final_emp_outcomes[x][6] - emotion_data_test_arr[x][6])\n",
        "\n",
        "average_MAE = average_MAE/len(final_emp_outcomes)\n",
        "\n",
        "print(average_MAE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13735747094028544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKE8f1kflhqs"
      },
      "source": [
        "print(sampled_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui8sWyrLqZ47"
      },
      "source": [
        "targets = [0.625, 0.875, 0.625, 0.625, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3veE9feXqWrn"
      },
      "source": [
        "print(sampled_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0iGoAMKf1P1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3083bb-d6ea-45b2-83fc-458726a0fb71"
      },
      "source": [
        "\n",
        "# make a prediction for new data\n",
        "row = [0.20,     0.60,     0.90,   0.33,   0.20,   0.47,  0.90,     0.47,      0.960]\n",
        "# row = [0.50, 0.75, 0.9, 0.30, 0.52, 0.18, 0.5, 0.30, 0.921]\n",
        "newX = asarray([row])\n",
        "yhat = model.predict(newX)\n",
        "prediction = yhat[0]\n",
        "print('Predicted: %s' % yhat[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [ 9.7613013e-01 -5.9173256e-04 -1.0264970e-02 -4.9635535e-03\n",
            " -4.5053903e-03  9.1708279e-01  6.1339512e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-jSnDkPSpX8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqKMPdxcf1Ns",
        "outputId": "0aeac781-1ef3-4be4-ad25-cca5e90006c2"
      },
      "source": [
        "# Defining a character's personality based on the Big Five Personality Model\n",
        "Openness = 0.4\n",
        "Conscientiousness = 0.8\n",
        "Extraversion = 0.6\n",
        "Agreeableness = 0.3\n",
        "Neuroticism = 0.4\n",
        "\n",
        "# Since, we do not have information about the participants in the trial. We assume that on an average the peope were in a slightly relaxed default mood.\n",
        "# The personality traits chosen are hence so. \n",
        "\n",
        "# Calculating default mood in the PAD space based on the above peronality characteristics\n",
        "Pleasure  = (0.21 * Extraversion) + (0.59 * Agreeableness)        + (0.19 * Neuroticism)\n",
        "Arousal   = (0.15 * Openness)     + (0.30 * Agreeableness)        - (0.57 * Neuroticism)\n",
        "Dominance = (0.25 * Openness)     + (0.17 * Conscientiousness)    + (0.60 * Extraversion)     - (0.32 * Agreeableness) \n",
        "\n",
        "DefaultMood_PAD = [Pleasure, Arousal, Dominance]\n",
        "\n",
        "print(\"Default Mood : \", DefaultMood_PAD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Mood :  [0.379, -0.07799999999999999, 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkbOhw9SHe7L"
      },
      "source": [
        "# PAD Mappings for Emotions\n",
        "# Mappings were not available for all emotions in the dataset. The emotions which were nearest in meaning and had mappings available were thus chosen.\n",
        "# Except Surprise, we could find alternatives for every other emotion. As a result Surprise was dropped from the dataset and thus the predictions.\n",
        "\n",
        "# Emotion (Dataset) <-------> Mapped Emotion in PAD Space\n",
        "# Happy             -         Joy\n",
        "# Sad               -         Remorse\n",
        "# Anger             -         Anger\n",
        "# Disgust           -         Shame\n",
        "# Fear              -         Fear\n",
        "# Content           -         Gratification\n",
        "# Disappointment    -         Disappointment\n",
        "\n",
        "Happy_Intensity              = prediction[0] if (prediction[0] > 0) else 0.0\n",
        "Sad_Intensity                = prediction[1] if (prediction[1] > 0) else 0.0\n",
        "Anger_Intensity              = prediction[2] if (prediction[2] > 0) else 0.0\n",
        "Disgust_Intensity            = prediction[3] if (prediction[3] > 0) else 0.0\n",
        "Fear_Intensity               = prediction[4] if (prediction[4] > 0) else 0.0\n",
        "Content_Intensity            = prediction[5] if (prediction[5] > 0) else 0.0\n",
        "Disappointment_Intensity     = prediction[6] if (prediction[6] > 0) else 0.0\n",
        "\n",
        "Happy_PAD           = [0.4, 0.2, -0.3]\n",
        "Sad_PAD             = [-0.3, 0.1, -0.6]\n",
        "Anger_PAD           = [-0.51, 0.59, 0.25]\n",
        "Disgust_PAD         = [-0.3, 0.1, -0.6]\n",
        "Fear_PAD            = [-0.64, 0.60, -0.43]\n",
        "Content_PAD         = [0.6, 0.5, 0.4]\n",
        "Disappointment_PAD  = [-0.3, 0.1, -0.4]\n",
        "\n",
        "Appraised_Intensities = [Happy_Intensity, Sad_Intensity, Anger_Intensity, Disgust_Intensity, Fear_Intensity, Content_Intensity, Disappointment_Intensity]\n",
        "Mapped_Emotions       = [Happy_PAD, Sad_PAD, Anger_PAD, Disgust_PAD, Fear_PAD, Content_PAD, Disappointment_PAD]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DOKAYxvHe26",
        "outputId": "aa5e97c9-0aa1-4ebf-e270-1c66bd9a4f5b"
      },
      "source": [
        "# Calculating Virtual Emotion Centre\n",
        "Summation_Intensities = Happy_Intensity + Sad_Intensity + Anger_Intensity + Disgust_Intensity + Fear_Intensity + Content_Intensity + Disappointment_Intensity\n",
        "\n",
        "VEC_P   = ( (Happy_Intensity * Happy_PAD[0]) + (Sad_Intensity * Sad_PAD[0]) + (Anger_Intensity * Anger_PAD[0]) + (Disgust_Intensity * Disgust_PAD[0]) + (Fear_Intensity * Fear_PAD[0]) + (Content_Intensity * Content_PAD[0]) + (Disappointment_Intensity * Disappointment_PAD[0])) / Summation_Intensities\n",
        "VEC_A   = ( (Happy_Intensity * Happy_PAD[1]) + (Sad_Intensity * Sad_PAD[1]) + (Anger_Intensity * Anger_PAD[1]) + (Disgust_Intensity * Disgust_PAD[1]) + (Fear_Intensity * Fear_PAD[1]) + (Content_Intensity * Content_PAD[1]) + (Disappointment_Intensity * Disappointment_PAD[1])) / Summation_Intensities\n",
        "VEC_D   = ( (Happy_Intensity * Happy_PAD[2]) + (Sad_Intensity * Sad_PAD[2]) + (Anger_Intensity * Anger_PAD[2]) + (Disgust_Intensity * Disgust_PAD[2]) + (Fear_Intensity * Fear_PAD[2]) + (Content_Intensity * Content_PAD[2]) + (Disappointment_Intensity * Disappointment_PAD[2])) / Summation_Intensities\n",
        "\n",
        "VEC_PAD = [VEC_P, VEC_A, VEC_D]\n",
        "print(\"Virtual Emotion Centre : \", VEC_PAD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Virtual Emotion Centre :  [0.49662300064054316, 0.34524219832751024, 0.03894164835951643]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2JtrDIIHe0r",
        "outputId": "2d8e491a-0d70-45af-b9ba-91f94579c8d5"
      },
      "source": [
        "print(Summation_Intensities/7.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27054661565593313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRbtNg87Heik",
        "outputId": "95a67240-4daf-4cdf-805a-dc8e424764f1"
      },
      "source": [
        "import math\n",
        "print(math.sqrt(math.pow(VEC_P, 2) + math.pow(VEC_A, 2) + math.pow(VEC_D, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6060883040021355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeHPbSUW1uAZ",
        "outputId": "6466c323-fd0b-47da-cddd-cec4d4fa4dea"
      },
      "source": [
        "print(math.sqrt(math.pow(Happy_Intensity * Happy_PAD[0], 2) + math.pow(Happy_Intensity * Happy_PAD[1], 2) + math.pow(Happy_Intensity * Happy_PAD[2], 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5256621611987398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-ZwpAA3EWTC",
        "outputId": "68554003-fd76-4753-d36b-c7660b08c7c0"
      },
      "source": [
        "print(math.sqrt(math.pow(VEC_P - DefaultMood_PAD[0], 2) + math.pow(VEC_A - DefaultMood_PAD[1], 2) + math.pow(VEC_D - DefaultMood_PAD[2], 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6368233132841703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcC4zpIbEh4L"
      },
      "source": [
        "def mood_push_and_pull(VEC_PAD, CurrentMood_PAD, push_intensity):\n",
        "  \n",
        "  dist_between_VEC_Current  = math.sqrt(math.pow(VEC_P - CurrentMood_PAD[0], 2) + math.pow(VEC_A - CurrentMood_PAD[1], 2) + math.pow(VEC_D - CurrentMood_PAD[2], 2))\n",
        "  scale = push_intensity/dist_between_VEC_Current\n",
        "\n",
        "  if (((VEC_PAD[0] * CurrentMood_PAD[0]) > 0) and ((VEC_PAD[1] * CurrentMood_PAD[1]) > 0) and ((VEC_PAD[2] * CurrentMood_PAD[2]) > 0) ):\n",
        "    if (VEC_PAD[0] >= 0):\n",
        "      if (CurrentMood_PAD[0] < VEC_PAD[0]):\n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (VEC_PAD[0] - CurrentMood_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (VEC_PAD[1] - CurrentMood_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (VEC_PAD[2] - CurrentMood_PAD[2]))\n",
        "      else:\n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (CurrentMood_PAD[0] - VEC_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (CurrentMood_PAD[1] - VEC_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (CurrentMood_PAD[2] - VEC_PAD[2]))\n",
        "    else:\n",
        "      if (CurrentMood_PAD[0] > VEC_PAD[0]):\n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (VEC_PAD[0] - CurrentMood_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (VEC_PAD[1] - CurrentMood_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (VEC_PAD[2] - CurrentMood_PAD[2]))\n",
        "      else:\n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (CurrentMood_PAD[0] - VEC_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (CurrentMood_PAD[1] - VEC_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (CurrentMood_PAD[2] - VEC_PAD[2]))\n",
        "  else :   \n",
        "        NewMood_P = CurrentMood_PAD[0] + (scale * (VEC_PAD[0] - CurrentMood_PAD[0]))\n",
        "        NewMood_A = CurrentMood_PAD[1] + (scale * (VEC_PAD[1] - CurrentMood_PAD[1]))\n",
        "        NewMood_D = CurrentMood_PAD[2] + (scale * (VEC_PAD[2] - CurrentMood_PAD[2]))\n",
        "\n",
        "  NewMood_PAD = [NewMood_P, NewMood_A, NewMood_D]\n",
        "  return NewMood_PAD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW1GAQOsy6Iv"
      },
      "source": [
        "CurrentMood_PAD = DefaultMood_PAD\n",
        "push_intensity = Summation_Intensities/7.0\n",
        "NewMood_PAD = mood_push_and_pull(VEC_PAD, CurrentMood_PAD, push_intensity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI6KXls2y6Ex",
        "outputId": "4d74454d-18d7-439b-dbcc-7a6ba2051251"
      },
      "source": [
        "print(NewMood_PAD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.4289706968679936, 0.1018092845718239, 0.30412498403529065]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v0WjCO9y6DP"
      },
      "source": [
        "P_Val = 1 if (Happy_PAD[0] * NewMood_PAD[0]) > 0 else -1\n",
        "A_Val = 1 if (Happy_PAD[1] * NewMood_PAD[1]) > 0 else -1\n",
        "D_Val = 1 if (Happy_PAD[2] * NewMood_PAD[2]) > 0 else -1\n",
        "\n",
        "New_Happy_P = Happy_PAD[0] * (1 + (0.25 * P_Val * NewMood_PAD[0]))\n",
        "New_Happy_A = Happy_PAD[1] * (1 + (0.25 * A_Val * NewMood_PAD[1]))\n",
        "New_Happy_D = Happy_PAD[2] * (1 + (0.25 * D_Val * NewMood_PAD[2]))\n",
        "\n",
        "New_Happy_PAD = [New_Happy_P, New_Happy_A, New_Happy_D]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzpQlgggy6Az",
        "outputId": "0602537f-9448-4bb0-88b0-9f3ff0977bc4"
      },
      "source": [
        "print(math.sqrt(math.pow(New_Happy_PAD[0], 2) + math.pow(New_Happy_PAD[1], 2) + math.pow(New_Happy_PAD[2], 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5612972083543027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSbZ0FKXRQiz",
        "outputId": "dd1912b8-3700-4a5e-c89b-17508592e5f6"
      },
      "source": [
        "print(math.sqrt(math.pow(Happy_PAD[0], 2) + math.pow(Happy_PAD[1], 2) + math.pow(Happy_PAD[2], 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5385164807134505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07oZgterRJ8P",
        "outputId": "4a7195c6-a72d-4d87-b864-93eb90d723ea"
      },
      "source": [
        "print(Happy_Intensity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9761301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9m6CdBRRcZQ",
        "outputId": "6fbddd54-b355-4aab-9512-85433ef8c565"
      },
      "source": [
        "print(0.548 * (0.468/0.538))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.47669888475836436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0rYcOGRMspY"
      },
      "source": [
        "New_Generated_Emotions = []\n",
        "\n",
        "for emotion in Mapped_Emotions:\n",
        "  P_Val = 1 if (emotion[0] * NewMood_PAD[0]) > 0 else -1\n",
        "  A_Val = 1 if (emotion[1] * NewMood_PAD[1]) > 0 else -1\n",
        "  D_Val = 1 if (emotion[2] * NewMood_PAD[2]) > 0 else -1\n",
        "\n",
        "  New_Emotion_P = emotion[0] * (1 + (0.25 * P_Val * NewMood_PAD[0]))\n",
        "  New_Emotion_A = emotion[1] * (1 + (0.25 * A_Val * NewMood_PAD[1]))\n",
        "  New_Emotion_D = emotion[2] * (1 + (0.25 * D_Val * NewMood_PAD[2]))\n",
        "\n",
        "  New_Emotion_PAD = [New_Emotion_P, New_Emotion_A, New_Emotion_D]\n",
        "  New_Generated_Emotions.append(New_Emotion_PAD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMRngF2DOO7C"
      },
      "source": [
        "Final_Intensities_Generated = []\n",
        "\n",
        "Original_Emotion_Norms = []\n",
        "New_Emotion_Norms =[]\n",
        "\n",
        "for emotion in Mapped_Emotions:\n",
        "  emotion_norm = math.sqrt(math.pow(emotion[0], 2) + math.pow(emotion[1], 2) + math.pow(emotion[2], 2))\n",
        "  Original_Emotion_Norms.append(emotion_norm)\n",
        "\n",
        "for new_emotion in New_Generated_Emotions:\n",
        "  new_emotion_norm  = math.sqrt(math.pow(new_emotion[0], 2) + math.pow(new_emotion[1], 2) + math.pow(new_emotion[2], 2))\n",
        "  New_Emotion_Norms.append(new_emotion_norm) \n",
        "\n",
        "for i in range(len(New_Emotion_Norms)):\n",
        "  final_emotion_intensity = (New_Emotion_Norms[i] * Appraised_Intensities[i])/Original_Emotion_Norms[i]\n",
        "  Final_Intensities_Generated.append(final_emotion_intensity)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8OT4XDnP_XE",
        "outputId": "789a6afd-310d-4cea-e27c-ff2af9f2593c"
      },
      "source": [
        "print(\"Final Emotion Intensities Generated : \")\n",
        "print(Final_Intensities_Generated)\n",
        "\n",
        "# 0.625  0.000  0.000     0.25   0.0    0.625   0.375"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Emotion Intensities Generated : \n",
            "[1.0174231159253175, 0.0, 0.0, 0.0, 0.0, 0.9856794353914962, 0.0005627543210580644]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vTGRCBcdKvv",
        "outputId": "61b54a93-c658-4c9b-fa47-62dd1cb06ec4"
      },
      "source": [
        "Final_Happy_Comparison = [0.504, 0.97, 0.498, 0.516, 0.987]\n",
        "average_MAE = 0\n",
        "\n",
        "for x in range(len(Final_Happy_Comparison)):\n",
        "  average_MAE += abs(Final_Happy_Comparison[x] - targets[x])\n",
        "\n",
        "average_MAE = average_MAE/5\n",
        "\n",
        "print(average_MAE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYo0ia8p3GUH"
      },
      "source": [
        "P_Val = 1 if (Disappointment_PAD[0] * NewMood_PAD[0]) > 0 else -1\n",
        "A_Val = 1 if (Disappointment_PAD[1] * NewMood_PAD[1]) > 0 else -1\n",
        "D_Val = 1 if (Disappointment_PAD[2] * NewMood_PAD[2]) > 0 else -1\n",
        "\n",
        "New_Disappointment_P = Disappointment_PAD[0] * (1 + (0.25 * P_Val * NewMood_PAD[0]))\n",
        "New_Disappointment_A = Disappointment_PAD[1] * (1 + (0.25 * A_Val * NewMood_PAD[1]))\n",
        "New_Disappointment_D = Disappointment_PAD[2] * (1 + (0.25 * D_Val * NewMood_PAD[2]))\n",
        "\n",
        "New_Disappointment_PAD = [New_Disappointment_P, New_Disappointment_A, New_Disappointment_D]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTRsKog2MuGz",
        "outputId": "dbbca605-8654-4d32-8124-799e41182c29"
      },
      "source": [
        "print(\"New_Emotion_PAD norm\")\n",
        "print(math.sqrt(math.pow(New_Disappointment_PAD[0], 2) + math.pow(New_Disappointment_PAD[1], 2) + math.pow(New_Disappointment_PAD[2], 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New_Emotion_PAD norm\n",
            "0.47838931111219074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs3-1EHvRw5L",
        "outputId": "194e7810-34f6-450d-8c0b-b84160eaf7bc"
      },
      "source": [
        "print(\"Original_Emotion_PAD norm\")\n",
        "print(math.sqrt(math.pow(Disappointment_PAD[0], 2) + math.pow(Disappointment_PAD[1], 2) + math.pow(Disappointment_PAD[2], 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original_Emotion_PAD norm\n",
            "0.5099019513592785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phl-SaI4MyoP",
        "outputId": "5e7bf5a2-be10-4dc2-b50d-2e09b51cecba"
      },
      "source": [
        "print(\"Intensity computed from appraisal\")\n",
        "print(Disappointment_Intensity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intensity computed from appraisal\n",
            "0.5288515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rtup5yKM9Oa",
        "outputId": "e9dabed7-a4b8-4a96-a38d-32f64ce98cbc"
      },
      "source": [
        "print(\"Final Intensity\")\n",
        "print(0.47 * (0.53/0.50))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Intensity\n",
            "0.4982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFpe-_1yR9zm"
      },
      "source": [
        "# -------------------------------------------- Extra (Rough Cells) [To be ignored] -----------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBUwsU6cQw0Q",
        "outputId": "22cf5d9d-d11d-434a-dbce-760187ffba69"
      },
      "source": [
        "!pip install torch torchvision pyro-ppl\n",
        "\n",
        "#import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.distributions import Normal\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "print(\"Currently using Pyro version: \" + pyro.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Collecting pyro-ppl\n",
            "  Downloading pyro_ppl-1.7.0-py3-none-any.whl (678 kB)\n",
            "\u001b[K     |████████████████████████████████| 678 kB 15.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (4.41.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.7.0\n",
            "Currently using Pyro version: 1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07Lt6wVjot-k",
        "outputId": "c54f5311-da64-4c88-eb89-03eb02396dd8"
      },
      "source": [
        "# data location\n",
        "#dataset_path = os.path.join(os.path.abspath('..'), \"CognitionData\", \"data_wheelOnly.csv\")\n",
        "dataset_path = \"https://desmond-ong.github.io/pplAffComp/CognitionData/data_wheelOnly.csv\"\n",
        "\n",
        "OUTCOME_VAR_NAMES = [\"payoff1\", \"payoff2\", \"payoff3\", \"prob1\", \"prob2\", \"prob3\", \"win\", \"winProb\", \"angleProp\"]\n",
        "EMOTION_VAR_NAMES = [\"happy\", \"sad\", \"anger\", \"surprise\", \"disgust\", \"fear\", \"content\", \"disapp\"]\n",
        "OUTCOME_VAR_DIM = len(OUTCOME_VAR_NAMES)\n",
        "EMOTION_VAR_DIM = len(EMOTION_VAR_NAMES)\n",
        "\n",
        "def load_outcome_emotion_dataset(csv_file, normalize_values=True, preview_datafile=False):\n",
        "    data_readin = pd.read_csv(csv_file)\n",
        "    outcome_data = data_readin.loc[:,OUTCOME_VAR_NAMES]\n",
        "    if normalize_values:\n",
        "        ####\n",
        "        ## payoff1, payoff2, payoff3 and win are between 0 and 100\n",
        "        ## need to normalize to [0,1] to match the rest of the variables,\n",
        "        ## by dividing payoff1, payoff2, payoff3 and win by 100\n",
        "        ####\n",
        "        outcome_data.loc[:,\"payoff1\"] = outcome_data.loc[:,\"payoff1\"]/100\n",
        "        outcome_data.loc[:,\"payoff2\"] = outcome_data.loc[:,\"payoff2\"]/100\n",
        "        outcome_data.loc[:,\"payoff3\"] = outcome_data.loc[:,\"payoff3\"]/100\n",
        "        outcome_data.loc[:,\"win\"]     = outcome_data.loc[:,\"win\"]/100\n",
        "    outcome_data_tensor = torch.tensor(outcome_data.values).type(torch.Tensor)\n",
        "    \n",
        "    emotion_data = data_readin.loc[:,EMOTION_VAR_NAMES]\n",
        "    if normalize_values:\n",
        "        ## note that emotions are transformed from a 9 point Likert to [0,1] via emo <- (emo-1)/8\n",
        "        emotion_data   = (emotion_data-1)/8\n",
        "    emotion_data_tensor = torch.tensor(emotion_data.values).type(torch.Tensor)\n",
        "    \n",
        "    if preview_datafile:\n",
        "        print(\"Preview of first 3 rows:\")\n",
        "        print(outcome_data.loc[0:2,:])\n",
        "        print(emotion_data.loc[0:2,:])\n",
        "    \n",
        "    data = torch.cat((outcome_data_tensor, emotion_data_tensor), 1)\n",
        "    # return data\n",
        "    return outcome_data, emotion_data\n",
        "\n",
        "\n",
        "# reads in datafile.\n",
        "print(\"Reading in dataset...\")\n",
        "# outcome_emotion_dataset = load_outcome_emotion_dataset(csv_file=dataset_path, preview_datafile=True)\n",
        "outcome_data, emotion_data = load_outcome_emotion_dataset(csv_file=dataset_path, preview_datafile=True)\n",
        "\n",
        "# outcome_data = outcome_emotion_dataset[:, :(OUTCOME_VAR_DIM)]\n",
        "# emotion_data = outcome_emotion_dataset[:, (OUTCOME_VAR_DIM):]\n",
        "\n",
        "print(\"OED : \", outcome_data.shape)\n",
        "\n",
        "# N_samples = outcome_emotion_dataset.shape[0]\n",
        "\n",
        "# print(\"Shape of dataset: \", outcome_emotion_dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading in dataset...\n",
            "Preview of first 3 rows:\n",
            "   payoff1  payoff2  payoff3  prob1  prob2  prob3  win  winProb  angleProp\n",
            "0     0.50     0.75      0.9   0.30   0.52   0.18  0.5     0.30      0.921\n",
            "1     0.15     0.70      0.8   0.45   0.29   0.26  0.8     0.26      0.873\n",
            "2     0.50     0.75      0.9   0.30   0.52   0.18  0.5     0.30      0.467\n",
            "   happy    sad  anger  surprise  disgust  fear  content  disapp\n",
            "0  0.625  0.000  0.000     0.625     0.25   0.0    0.625   0.375\n",
            "1  0.875  0.000  0.000     1.000     0.00   0.0    0.000   0.000\n",
            "2  0.625  0.125  0.125     0.250     0.00   0.0    0.250   0.500\n",
            "OED :  (1541, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDs9Q4SutKqs"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from numpy import asarray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwVfCYjovsfk"
      },
      "source": [
        "def get_model(n_inputs, n_outputs):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(320, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(160, input_dim=320, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(80, input_dim=160, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(40, input_dim=80, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(n_outputs))\n",
        "  model.compile(loss='mae', optimizer='adam')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T7cujQGyTM4"
      },
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "from numpy import mean\n",
        "from numpy import std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmeaIF67yCsY"
      },
      "source": [
        "def evaluate_model(X, y):\n",
        "\tresults = list()\n",
        "\tn_inputs, n_outputs = X.shape[1], y.shape[1]\n",
        "\t# define evaluation procedure\n",
        "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\t# enumerate folds\n",
        "\tfor train_ix, test_ix in cv.split(X):\n",
        "\t\t# prepare data\n",
        "    # x.iloc[list(train_index)], x.iloc[list(test_index)]\n",
        "\t\tX_train, X_test = X.iloc[list(train_ix)], X.iloc[list(test_ix)]\n",
        "\t\ty_train, y_test = y.iloc[list(train_ix)], y.iloc[list(test_ix)]\n",
        "\t\t# define model\n",
        "\t\tmodel = get_model(n_inputs, n_outputs)\n",
        "\t\t# fit modelb\n",
        "\t\tmodel.fit(X_train, y_train, verbose=0, epochs=100)\n",
        "\t\t# evaluate model on test set\n",
        "\t\tmae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\t\t# store result\n",
        "\t\tprint('>%.3f' % mae)\n",
        "\t\tresults.append(mae)\n",
        "\treturn results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP_9F6-HyKed",
        "outputId": "7e773aef-d415-4b4d-a699-905b3245c54f"
      },
      "source": [
        "# evaluate model\n",
        "print(outcome_data)\n",
        "results = evaluate_model(outcome_data, emotion_data)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      payoff1  payoff2  payoff3  prob1  prob2  prob3   win  winProb  angleProp\n",
            "0        0.50     0.75     0.90   0.30   0.52   0.18  0.50     0.30      0.921\n",
            "1        0.15     0.70     0.80   0.45   0.29   0.26  0.80     0.26      0.873\n",
            "2        0.50     0.75     0.90   0.30   0.52   0.18  0.50     0.30      0.467\n",
            "3        0.00     0.40     0.95   0.27   0.40   0.33  0.40     0.40      0.615\n",
            "4        0.20     0.60     0.90   0.33   0.20   0.47  0.90     0.47      0.960\n",
            "...       ...      ...      ...    ...    ...    ...   ...      ...        ...\n",
            "1536     0.50     0.75     0.90   0.30   0.52   0.18  0.50     0.30      0.158\n",
            "1537     0.45     0.60     0.90   0.52   0.29   0.19  0.60     0.29      0.987\n",
            "1538     0.15     0.70     0.80   0.45   0.29   0.26  0.80     0.26      0.678\n",
            "1539     0.15     0.70     0.80   0.45   0.29   0.26  0.80     0.26      0.420\n",
            "1540     0.25     0.60     1.00   0.45   0.37   0.18  0.25     0.45      0.106\n",
            "\n",
            "[1541 rows x 9 columns]\n",
            ">0.139\n",
            ">0.142\n",
            ">0.145\n",
            ">0.139\n",
            ">0.135\n",
            ">0.146\n",
            ">0.153\n",
            ">0.143\n",
            ">0.131\n",
            ">0.149\n",
            ">0.149\n",
            ">0.134\n",
            ">0.165\n",
            ">0.144\n",
            ">0.129\n",
            ">0.152\n",
            ">0.136\n",
            ">0.142\n",
            ">0.135\n",
            ">0.136\n",
            ">0.137\n",
            ">0.146\n",
            ">0.138\n",
            ">0.127\n",
            ">0.145\n",
            ">0.138\n",
            ">0.148\n",
            ">0.154\n",
            ">0.133\n",
            ">0.155\n",
            "MAE: 0.142 (0.008)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV8sTj7NseZ4",
        "outputId": "7033b10c-88ce-4d49-b0df-275b12eb4131"
      },
      "source": [
        "\n",
        "n_inputs, n_outputs = outcome_data.shape[1], emotion_data.shape[1]\n",
        "# get model\n",
        "model = get_model(n_inputs, n_outputs)\n",
        "# fit the model on all data\n",
        "model.fit(outcome_data, emotion_data, verbose=0, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48921f2f50>"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U9Vk8Rwsde_",
        "outputId": "0d9776c6-5f7c-43b0-e98e-749ca5a65c61"
      },
      "source": [
        "# make a prediction for new data\n",
        "row = [0.15, 0.70, 0.8, 0.45, 0.29, 0.26, 0.8, 0.26, 0.873]\n",
        "# row = [0.50, 0.75, 0.9, 0.30, 0.52, 0.18, 0.5, 0.30, 0.921]\n",
        "newX = asarray([row])\n",
        "yhat = model.predict(newX)\n",
        "print('Predicted: %s' % yhat[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: [ 0.9869102   0.00726712 -0.00236034  0.8195064   0.00606611 -0.00702659\n",
            "  0.8905076   0.00221627]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEfdsx5Co9pk"
      },
      "source": [
        "# As per Ong 2015\n",
        "def compute_appraisal(outcome_data):\n",
        "    # We have simple hard-coded appraisals, for illustration\n",
        "    # This is following Ong, Zaki, & Goodman (2015)\n",
        "    # the outcome data columns are, in order:\n",
        "    # [\"payoff1\", \"payoff2\", \"payoff3\", \"prob1\", \"prob2\", \"prob3\", \"win\", \"winProb\", \"angleProp\"]\n",
        "    # the 3 appraisal variables are: \n",
        "    #     amount won (\"win\"),\n",
        "    #     Prediction Error PE = win - EV, where EV = prob1*payoff1 + prob2*payoff2 + prob3*payoff3\n",
        "    #     absolute value of PE\n",
        "    \n",
        "    # if outcome_data only has 1 observation, reshape so vectorization works\n",
        "    if(len(outcome_data.shape)==1):\n",
        "        outcome_data = outcome_data.view(1,9)\n",
        "        print(outcome_data.shape)\n",
        "    \n",
        "    # initializing appraisalVals\n",
        "    appraisalVals = torch.zeros(size=(outcome_data.shape[0],3))\n",
        "    appraisalVals[:,0] = outcome_data[:,6] # amount won\n",
        "    \n",
        "    # Expected value\n",
        "    EV = outcome_data[:,0] * outcome_data[:,3] + \\\n",
        "         outcome_data[:,1] * outcome_data[:,4] + \\\n",
        "         outcome_data[:,2] * outcome_data[:,5]\n",
        "    \n",
        "    # prediction error and absolute PE\n",
        "    appraisalVals[:,1] = appraisalVals[:,0] - EV\n",
        "    appraisalVals[:,2] = abs(appraisalVals[:,1])\n",
        "    return(appraisalVals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Hm1-IasMjl"
      },
      "source": [
        "def fit_regression_model(data):\n",
        "    # define the parameters that control the gaussian prior over the regression coeffs.\n",
        "    # mean = 0, scale = 1\n",
        "    coeff_mean_prior = torch.tensor(0.0)\n",
        "    coeff_scale_prior = torch.tensor(1.0)\n",
        "    \n",
        "    # sample b_0 (intercept) and b_1 to b_3 (regression coeffs)\n",
        "    b_0 = pyro.sample(\"b_0\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
        "    b_1 = pyro.sample(\"b_1\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
        "    b_2 = pyro.sample(\"b_2\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
        "    b_3 = pyro.sample(\"b_3\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
        "    \n",
        "    # loop over observed data\n",
        "    with pyro.plate(\"map\"):\n",
        "        outcome_data = data[:, :(OUTCOME_VAR_DIM)]\n",
        "        \n",
        "        # Here, for simplification, we are only taking one emotion variable (happy)\n",
        "        # instead of all 8 emotions\n",
        "        emotion_data = data[:, OUTCOME_VAR_DIM ]  \n",
        "        appraisal_vars = compute_appraisal(outcome_data)\n",
        "        \n",
        "        # run the regression forward\n",
        "        prediction = b_0 + b_1 * appraisal_vars[:,0] + b_2 * appraisal_vars[:,1] + b_3 * appraisal_vars[:,2]\n",
        "        # condition on the observed data\n",
        "        pyro.sample(\"obs\", Normal(prediction, 1), obs = emotion_data)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "aO2bXroDhziU",
        "outputId": "79679ebf-0a7a-4c77-fa52-719a46d53ad2"
      },
      "source": [
        "emotion_data = outcome_emotion_dataset[:, (OUTCOME_VAR_DIM):]\n",
        "print(emotion_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9d4f08934e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memotion_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutcome_emotion_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOUTCOME_VAR_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'outcome_emotion_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyJg4fS4loUB"
      },
      "source": [
        "def fit_regression_guide(data):\n",
        "    mean_b0_param  = pyro.param(\"guide_mean_b0\",  torch.tensor(0.0))\n",
        "    scale_b0_param = pyro.param(\"guide_scale_b0\", torch.tensor(1.0))\n",
        "    mean_b1_param  = pyro.param(\"guide_mean_b1\",  torch.tensor(0.0))\n",
        "    scale_b1_param = pyro.param(\"guide_scale_b1\", torch.tensor(1.0))\n",
        "    mean_b2_param  = pyro.param(\"guide_mean_b2\",  torch.tensor(0.0))\n",
        "    scale_b2_param = pyro.param(\"guide_scale_b2\", torch.tensor(1.0))\n",
        "    mean_b3_param  = pyro.param(\"guide_mean_b3\",  torch.tensor(0.0))\n",
        "    scale_b3_param = pyro.param(\"guide_scale_b3\", torch.tensor(1.0))\n",
        "    \n",
        "    # sample coefficients from Normal(mean, scale)\n",
        "    pyro.sample(\"b_0\", Normal(mean_b0_param, scale_b0_param))\n",
        "    pyro.sample(\"b_1\", Normal(mean_b1_param, scale_b1_param))\n",
        "    pyro.sample(\"b_2\", Normal(mean_b2_param, scale_b2_param))\n",
        "    pyro.sample(\"b_3\", Normal(mean_b3_param, scale_b3_param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRn5BhHTum4d"
      },
      "source": [
        "# this line clears pyro's parameter store.\n",
        "pyro.clear_param_store()\n",
        "\n",
        "num_iterations = 1000\n",
        "\n",
        "# setup the optimizer with some learning rate\n",
        "optimizer = Adam({\"lr\": 0.005})\n",
        "\n",
        "# setup the inference algorithm\n",
        "svi = SVI(fit_regression_model, fit_regression_guide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "# do gradient steps\n",
        "losses = []\n",
        "for thisIteration in range(num_iterations):\n",
        "    # calculate the loss and take a gradient step\n",
        "    thisLoss = svi.step(outcome_emotion_dataset)\n",
        "    losses.append(thisLoss)\n",
        "    if thisIteration % 100 == 0:\n",
        "        print(\"[iteration %04d] loss: %.4f\" % (thisIteration + 1, thisLoss / float(N_samples)))\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(\"ELBO\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L9EsN5xwbxr"
      },
      "source": [
        "# output the learned variational parameters\n",
        "print(\"b0 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_mean_b0\").item(), pyro.param(\"guide_scale_b0\").item()))\n",
        "print(\"b1 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_mean_b1\").item(), pyro.param(\"guide_scale_b1\").item()))\n",
        "print(\"b2 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_mean_b2\").item(), pyro.param(\"guide_scale_b2\").item()))\n",
        "print(\"b3 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_mean_b3\").item(), pyro.param(\"guide_scale_b3\").item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9k1v-heJSAH"
      },
      "source": [
        "b_0 = pyro.sample(\"b_0\", Normal(pyro.param(\"guide_mean_b0\").item(), pyro.param(\"guide_scale_b0\").item()))\n",
        "b_1 = pyro.sample(\"b_1\", Normal(pyro.param(\"guide_mean_b1\").item(), pyro.param(\"guide_scale_b1\").item()))\n",
        "b_2 = pyro.sample(\"b_2\", Normal(pyro.param(\"guide_mean_b2\").item(), pyro.param(\"guide_scale_b2\").item()))\n",
        "b_3 = pyro.sample(\"b_3\", Normal(pyro.param(\"guide_mean_b3\").item(), pyro.param(\"guide_scale_b3\").item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3JLrMu9JH70"
      },
      "source": [
        "new_data = torch.tensor([0.50, 0.75, 0.9, 0.30, 0.52, 0.18, 0.5, 0.30, 0.921])\n",
        "appraised_data = compute_appraisal(new_data)\n",
        "print(appraised_data)\n",
        "new_prediction = b_0 + b_1 * appraised_data[0][0] + b_2 * appraised_data[0][1] + b_3 * appraised_data[0][2]  \n",
        "print(new_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcSMyzSVw-f9"
      },
      "source": [
        "## Extensions to linear regressionb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdNq6vUPnDR6"
      },
      "source": [
        "class appraisalRegressionModule(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(appraisalRegressionModule, self).__init__()\n",
        "        self.linear = nn.Linear(num_features, 8)\n",
        "\n",
        "    def forward(self, outcome):\n",
        "        return self.linear(outcome)\n",
        "\n",
        "regression_model = appraisalRegressionModule(OUTCOME_VAR_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1udrfvXDmKXz"
      },
      "source": [
        "def bayesianRegressionModel(data, y):\n",
        "    # Create unit normal priors over the parameters\n",
        "    weights_loc   = torch.zeros(size=(torch.Size((1, OUTCOME_VAR_DIM))))\n",
        "    weights_scale = torch.ones(size=(torch.Size((1, OUTCOME_VAR_DIM))))\n",
        "    weights_prior = Normal(weights_loc, weights_scale).independent(1)\n",
        "    \n",
        "    # location and scale prior for the bias\n",
        "    bias_loc   = torch.zeros(size=(torch.Size((1, ))))\n",
        "    bias_scale = torch.ones(size=(torch.Size((1, ))))\n",
        "    bias_prior = Normal(bias_loc, bias_scale).independent(1)\n",
        "    \n",
        "    priors = {'linear.weight': weights_prior, 'linear.bias': bias_prior}\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", regression_model, priors)\n",
        "    # sample a model (which also samples from weights_prior and bias_prior)\n",
        "    sampled_regression_model = lifted_module()\n",
        "    \n",
        "    with pyro.plate(\"map\"):\n",
        "        # outcome_data = data[:, :(OUTCOME_VAR_DIM)]\n",
        "        \n",
        "        # Here, for simplification, we are only taking one emotion variable (happy)\n",
        "        # instead of all 8 emotions\n",
        "        # emotion_data = data[:, (OUTCOME_VAR_DIM):]  \n",
        "        # print(\"Emotion Data : \", emotion_data)\n",
        "        # print(\"Emotion Data Shape :\", emotion_data.shape)\n",
        "        \n",
        "        # run the regressor forward conditioned on data\n",
        "        prediction = sampled_regression_model(data).squeeze(-1)\n",
        "        print(\"Prediction : \", prediction)\n",
        "        \n",
        "        # condition on the observed data\n",
        "        pyro.sample(\"obs\", Normal(prediction, 1), obs = y)\n",
        "        # pyro.condition(bayesianRegressionModel, data = emotion_data)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1QK3wLGmLSu"
      },
      "source": [
        "def bayesianRegressionGuide(data, y):\n",
        "    # define our variational parameters\n",
        "    weights_loc   = torch.randn(1, OUTCOME_VAR_DIM)\n",
        "    # Note that the scale has to be non-negative. Thus, we use exp() to get a non-negative number.\n",
        "    # we also use a narrower scale (exp(-1) ~ 0.35 instead of exp(0) = 1)\n",
        "    weights_scale = torch.exp(-1.0 * torch.ones(1, OUTCOME_VAR_DIM) + 0.05 * torch.randn(1, OUTCOME_VAR_DIM))\n",
        "    bias_loc      = torch.randn(1)\n",
        "    bias_scale    = torch.exp(-1.0 * torch.ones(1) + 0.05 * torch.randn(1))\n",
        "\n",
        "    # using pyro.param() to register the variational parameters\n",
        "    weight_loc_param   = pyro.param(\"guide_loc_weight\", weights_loc)\n",
        "    weight_scale_param = pyro.param(\"guide_scale_weight\", weights_scale)\n",
        "    bias_loc_param     = pyro.param(\"guide_loc_bias\", bias_loc)\n",
        "    bias_scale_param   = pyro.param(\"guide_scale_bias\", bias_scale)\n",
        "    # guide distributions for w and b\n",
        "    weight_dist = Normal(weight_loc_param, weight_scale_param).independent(1)\n",
        "    bias_dist   = Normal(bias_loc_param, bias_scale_param).independent(1)\n",
        "    dists = {'linear.weight': weight_dist, 'linear.bias': bias_dist}\n",
        "    # lift the module and sample from that distribution\n",
        "    lifted_module = pyro.random_module(\"module\", regression_model, dists)\n",
        "    return lifted_module()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTF1HHm5mm_-"
      },
      "source": [
        "pyro.clear_param_store()\n",
        "\n",
        "num_iterations = 1000\n",
        "\n",
        "# setup the optimizer with some learning rate\n",
        "optimizer = Adam({\"lr\": 0.005})\n",
        "\n",
        "# setup the inference algorithm\n",
        "bayesianRegressionSVI = SVI(bayesianRegressionModel, bayesianRegressionGuide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "print(\"Outcome Data Shape : \", outcome_data.shape)\n",
        "print(\"Emotion Data Shape : \", emotion_data.shape)\n",
        "\n",
        "# do gradient steps\n",
        "losses = []\n",
        "for thisIteration in range(num_iterations):\n",
        "    # calculate the loss and take a gradient step\n",
        "    # thisLoss = bayesianRegressionSVI.step(outcome_emotion_dataset)\n",
        "    thisLoss = bayesianRegressionSVI.step(outcome_data, emotion_data)\n",
        "    losses.append(thisLoss)\n",
        "    if thisIteration % 100 == 0:\n",
        "        print(\"[iteration %04d] loss: %.4f\" % (thisIteration + 1, thisLoss / float(N_samples)))\n",
        "        \n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(\"ELBO\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPE1Om2OmqqG"
      },
      "source": [
        "#for name in pyro.get_param_store().get_all_param_names():\n",
        "#    print(name, pyro.param(name).data.numpy())\n",
        "\n",
        "guide_loc_weight = pyro.param(\"guide_loc_weight\")[0]\n",
        "guide_scale_weight = pyro.param(\"guide_scale_weight\")[0]\n",
        "\n",
        "print(\"b0 ~ Normal(%.4f, %.4f)\" % (pyro.param(\"guide_loc_bias\").item(), pyro.param(\"guide_scale_bias\").item()))\n",
        "for j in range(len(guide_loc_weight)):\n",
        "    print(\"b%1d\" % (j+1), \"~ Normal(%.4f, %.4f)\" % (guide_loc_weight[j], guide_scale_weight[j]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XjZ7xyIgL7R"
      },
      "source": [
        "b_0 = pyro.sample(\"b_0\", Normal(pyro.param(\"guide_loc_bias\").item(), pyro.param(\"guide_scale_bias\").item()))\n",
        "b_1 = pyro.sample(\"b_1\", Normal(guide_loc_weight[0], guide_scale_weight[0]))\n",
        "b_2 = pyro.sample(\"b_2\", Normal(guide_loc_weight[1], guide_scale_weight[1]))\n",
        "b_3 = pyro.sample(\"b_3\", Normal(guide_loc_weight[2], guide_scale_weight[2]))\n",
        "b_4 = pyro.sample(\"b_4\", Normal(guide_loc_weight[3], guide_scale_weight[3]))\n",
        "b_5 = pyro.sample(\"b_5\", Normal(guide_loc_weight[4], guide_scale_weight[4]))\n",
        "b_6 = pyro.sample(\"b_6\", Normal(guide_loc_weight[5], guide_scale_weight[5]))\n",
        "b_7 = pyro.sample(\"b_7\", Normal(guide_loc_weight[6], guide_scale_weight[6]))\n",
        "b_8 = pyro.sample(\"b_8\", Normal(guide_loc_weight[7], guide_scale_weight[7]))\n",
        "b_9 = pyro.sample(\"b_9\", Normal(guide_loc_weight[8], guide_scale_weight[8]))\n",
        "# print(b_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCLuWZIrfWz2"
      },
      "source": [
        "new_data = [0.50, 0.75, 0.9, 0.30, 0.52, 0.18, 0.5, 0.30, 0.921]\n",
        "new_prediction = b_0 + b_1 * new_data[0] + b_2 * new_data[1] + b_3 * new_data[2] + b_4 * new_data[3] + b_5 * new_data[4] + b_6 * new_data[5] + b_7 * new_data[6] + b_8 * new_data[7] + b_9 * new_data[8] \n",
        "print(new_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_zJnRm1VUX_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZdoxyX9VVZi"
      },
      "source": [
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.nn import PyroModule, PyroSample\n",
        "import torch.nn as nn\n",
        "from pyro.infer.autoguide import AutoDiagonalNormal\n",
        "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
        "from tqdm.auto import trange, tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Er95B_VVqC"
      },
      "source": [
        "class Model(PyroModule):\n",
        "    def __init__(self, h1=20, h2=8):\n",
        "        super().__init__()\n",
        "        self.fc1 = PyroModule[nn.Linear](1, h1)\n",
        "        self.fc1.weight = PyroSample(dist.Normal(0., 1.).expand([h1, 1]).to_event(2))\n",
        "        self.fc1.bias = PyroSample(dist.Normal(0., 1.).expand([h1]).to_event(1))\n",
        "        self.fc2 = PyroModule[nn.Linear](h1, h2)\n",
        "        self.fc2.weight = PyroSample(dist.Normal(0., 1.).expand([h2, h1]).to_event(2))\n",
        "        self.fc2.bias = PyroSample(dist.Normal(0., 1.).expand([h2]).to_event(1))\n",
        "        self.fc3 = PyroModule[nn.Linear](h2, 1)\n",
        "        self.fc3.weight = PyroSample(dist.Normal(0., 1.).expand([1, h2]).to_event(2))\n",
        "        self.fc3.bias = PyroSample(dist.Normal(0., 1.).expand([1]).to_event(1))\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = x.reshape(-1, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        mu = self.fc3(x).squeeze()\n",
        "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.))\n",
        "        with pyro.plate(\"data\", x.shape[0]):\n",
        "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma), obs=y)\n",
        "        return mu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZScspP_VV4a"
      },
      "source": [
        "model = Model()\n",
        "guide = AutoDiagonalNormal(model)\n",
        "adam = pyro.optim.Adam({\"lr\": 1e-3})\n",
        "svi = SVI(model, guide, adam, loss=Trace_ELBO())\n",
        "\n",
        "pyro.clear_param_store()\n",
        "bar = trange(20000)\n",
        "# x_train = torch.from_numpy(x).float()\n",
        "# y_train = torch.from_numpy(y).float()\n",
        "for epoch in bar:\n",
        "    loss = svi.step(outcome_data, emotion_data)\n",
        "    bar.set_postfix(loss=f'{loss / outcome_data.shape[0]:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh9l-dYFVWH9"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRZA1665j9B7"
      },
      "source": [
        "def get_train_and_test_splits(dataset, train_size, batch_size=1):\n",
        "    # We prefetch with a buffer the same size as the dataset because th dataset\n",
        "    # is very small and fits into memory.\n",
        "    # dataset = (\n",
        "    #     tfds.load(name=\"wine_quality\", as_supervised=True, split=\"train\")\n",
        "    #     .map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "    #     .prefetch(buffer_size=dataset_size)\n",
        "    #     .cache()\n",
        "    # )\n",
        "    # We shuffle with a buffer the same size as the dataset.\n",
        "    # print(\"Dataset : \", dataset)\n",
        "\n",
        "    train_dataset = (\n",
        "        dataset.take(train_size).shuffle(buffer_size=train_size).batch(batch_size)\n",
        "    )\n",
        "    test_dataset = dataset.skip(train_size).batch(batch_size)\n",
        "\n",
        "    return train_dataset, test_dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1AIlif6VWVf"
      },
      "source": [
        "hidden_units = [8, 8]\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "def run_experiment(model, loss, train_dataset, test_dataset):\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
        "        loss=loss,\n",
        "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
        "    )\n",
        "\n",
        "    print(\"Start training the model...\")\n",
        "    model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)\n",
        "    print(\"Model training finished.\")\n",
        "    _, rmse = model.evaluate(train_dataset, verbose=0)\n",
        "    print(f\"Train RMSE: {round(rmse, 3)}\")\n",
        "\n",
        "    print(\"Evaluating model performance...\")\n",
        "    _, rmse = model.evaluate(test_dataset, verbose=0)\n",
        "    print(f\"Test RMSE: {round(rmse, 3)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex9tS5-4k90X"
      },
      "source": [
        "# FEATURE_NAMES = [\n",
        "#     \"fixed acidity\",\n",
        "#     \"volatile acidity\",\n",
        "#     \"citric acid\",\n",
        "#     \"residual sugar\",\n",
        "#     \"chlorides\",\n",
        "#     \"free sulfur dioxide\",\n",
        "#     \"total sulfur dioxide\",\n",
        "#     \"density\",\n",
        "#     \"pH\",\n",
        "#     \"sulphates\",\n",
        "#     \"alcohol\",\n",
        "# ]\n",
        "\n",
        "\n",
        "def create_model_inputs():\n",
        "    inputs = {}\n",
        "    for feature_name in OUTCOME_VAR_NAMES:\n",
        "        inputs[feature_name] = layers.Input(\n",
        "            name=feature_name, shape=(1,), dtype=tf.float32\n",
        "        )\n",
        "    return inputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVCgKWBjVWn-"
      },
      "source": [
        "def create_baseline_model():\n",
        "    inputs = create_model_inputs()\n",
        "    print(\"Inputs : \", inputs)\n",
        "    \n",
        "    input_values = [value for _, value in sorted(inputs.items())]\n",
        "    features = keras.layers.concatenate(input_values)\n",
        "    features = layers.BatchNormalization()(features)\n",
        "\n",
        "    # Create hidden layers with deterministic weights using the Dense layer.\n",
        "    for units in hidden_units:\n",
        "        features = layers.Dense(units, activation=\"sigmoid\")(features)\n",
        "    # The output is deterministic: a single point estimate.\n",
        "    outputs = layers.Dense(units=8)(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uktWAdDxle63"
      },
      "source": [
        "dataset_size = 1541\n",
        "batch_size = 256\n",
        "train_size = int(dataset_size * 0.85)\n",
        "outcome_emotion_tfdataset = tf.data.Dataset.from_tensors(outcome_emotion_dataset)\n",
        "# print(outcome_emotion_tfdataset)\n",
        "train_dataset, test_dataset = get_train_and_test_splits(outcome_emotion_tfdataset, train_size, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yKELO_bVW8f"
      },
      "source": [
        "num_epochs = 100\n",
        "mse_loss = keras.losses.MeanSquaredError()\n",
        "baseline_model = create_baseline_model()\n",
        "run_experiment(baseline_model, mse_loss, train_dataset, test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE71fyLAVXKE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "252sKs4omwdz"
      },
      "source": [
        "# Defining a character's personality based on the Big Five Personality Model\n",
        "Openness = 0.4\n",
        "Conscientiousness = 0.8\n",
        "Extraversion = 0.6\n",
        "Agreeableness = 0.3\n",
        "Neuroticism = 0.4\n",
        "\n",
        "# Calculating default mood in the PAD space based on the above peronality characteristics\n",
        "Pleasure  = (0.21 * Extraversion) + (0.59 * Agreeableness)        + (0.19 * Neuroticism)\n",
        "Arousal   = (0.15 * Openness)     + (0.30 * Agreeableness)        - (0.57 * Neuroticism)\n",
        "Dominance = (0.25 * Openness)     + (0.17 * Conscientiousness)    + (0.60 * Extraversion)     - (0.32 * Agreeableness) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}